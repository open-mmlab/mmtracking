{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
      "metadata": {
        "id": "a9d79da1-6001-4f97-8381-b11b5516e640",
        "tags": []
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/open-mmlab/mmtracking/blob/master/demo/MMTracking_Tutorial.ipynb)\n",
        "\n",
        "# **Welcome to MMTracking**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547",
      "metadata": {
        "id": "527a563a-c8b2-44f0-ae20-0d226ab1e547"
      },
      "source": [
        "In this tutorial, you will learn to:\n",
        "+ Install MMTracking.\n",
        "+ Perform inference with pretrained weights in MMTracking.\n",
        "+ Train a new MOT model with a toy dataset.\n",
        "Let's start!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2c382c-a169-46fe-938f-c6687d763e8e",
      "metadata": {
        "id": "ab2c382c-a169-46fe-938f-c6687d763e8e"
      },
      "source": [
        "## **Install MMTracking**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8ced8f4-b07b-4216-8953-f7af6928b77c",
        "outputId": "b078d371-b978-4c10-fc9b-d4b45e6c5a40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check nvcc version\n",
        "!nvcc -V\n",
        "# Check GCC version\n",
        "!gcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b4f093f-e197-42bd-ba64-dc905e379382",
        "outputId": "b82ac7ec-2f1c-4d53-95e3-3b4d365a9ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.10.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (2137.6 MB)\n",
            "\u001b[K     |████████████▌                   | 834.1 MB 1.3 MB/s eta 0:16:48tcmalloc: large alloc 1147494400 bytes == 0x394ce000 @  0x7fd48a2f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |███████████████▉                | 1055.7 MB 1.2 MB/s eta 0:14:29tcmalloc: large alloc 1434370048 bytes == 0x7db24000 @  0x7fd48a2f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████            | 1336.2 MB 1.2 MB/s eta 0:11:02tcmalloc: large alloc 1792966656 bytes == 0x2956000 @  0x7fd48a2f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |█████████████████████████▎      | 1691.1 MB 1.2 MB/s eta 0:06:08tcmalloc: large alloc 2241208320 bytes == 0x6d73e000 @  0x7fd48a2f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2137645056 bytes == 0xf30a0000 @  0x7fd48a2f11e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n",
            "tcmalloc: large alloc 2672058368 bytes == 0x1e6bf6000 @  0x7fd48a2f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n",
            "\u001b[K     |████████████████████████████████| 2137.6 MB 399 bytes/s \n",
            "\u001b[?25hCollecting torchvision==0.11.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.11.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (21.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.9 MB 556 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.10.0\n",
            "  Downloading https://download.pytorch.org/whl/rocm4.1/torchaudio-0.10.0%2Brocm4.1-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 59.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0+cu111) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.11.0+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.10.0+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.10.0+cu111 torchaudio-0.10.0+rocm4.1 torchvision-0.11.0+cu111\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.1.0-py3-none-any.whl (280 kB)\n",
            "\u001b[K     |████████████████████████████████| 280 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmengine) (4.6.0.66)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 61.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmengine) (3.2.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from mmengine) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmengine) (6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmengine) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmengine) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmengine) (1.15.0)\n",
            "Installing collected packages: yapf, addict, mmengine\n",
            "Successfully installed addict-2.4.0 mmengine-0.1.0 yapf-0.32.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
            "Collecting mmcv>=2.0.0rc1\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/mmcv-2.0.0rc1-cp37-cp37m-manylinux1_x86_64.whl (47.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.5 MB 173 kB/s \n",
            "\u001b[?25hRequirement already satisfied: mmengine in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (0.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (21.3)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (6.0)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (4.6.0.66)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (1.21.6)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv>=2.0.0rc1) (0.32.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from mmengine->mmcv>=2.0.0rc1) (1.1.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmengine->mmcv>=2.0.0rc1) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine->mmcv>=2.0.0rc1) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine->mmcv>=2.0.0rc1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine->mmcv>=2.0.0rc1) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmengine->mmcv>=2.0.0rc1) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmengine->mmcv>=2.0.0rc1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmengine->mmcv>=2.0.0rc1) (1.15.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.0.0rc1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mmdet>=3.0.0rc0\n",
            "  Downloading mmdet-3.0.0rc0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet>=3.0.0rc0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet>=3.0.0rc0) (1.21.6)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet>=3.0.0rc0) (2.0.4)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet>=3.0.0rc0) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet>=3.0.0rc0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet>=3.0.0rc0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet>=3.0.0rc0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet>=3.0.0rc0) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet>=3.0.0rc0) (4.1.1)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-3.0.0rc0 terminaltables-3.1.10\n",
            "Cloning into 'mmtracking'...\n",
            "remote: Enumerating objects: 8692, done.\u001b[K\n",
            "remote: Counting objects: 100% (1182/1182), done.\u001b[K\n",
            "remote: Compressing objects: 100% (553/553), done.\u001b[K\n",
            "remote: Total 8692 (delta 682), reused 1044 (delta 611), pack-reused 7510\u001b[K\n",
            "Receiving objects: 100% (8692/8692), 3.10 MiB | 14.54 MiB/s, done.\n",
            "Resolving deltas: 100% (5522/5522), done.\n",
            "/content/mmtracking\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 1)) (0.29.32)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements/build.txt (line 2)) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Obtaining file:///content/mmtracking\n",
            "Collecting attributee\n",
            "  Downloading attributee-0.1.7.tar.gz (11 kB)\n",
            "Collecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 9.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (3.2.2)\n",
            "Collecting mmcls>=1.0.0rc0\n",
            "  Downloading mmcls-1.0.0rc0-py2.py3-none-any.whl (557 kB)\n",
            "\u001b[K     |████████████████████████████████| 557 kB 62.5 MB/s \n",
            "\u001b[?25hCollecting motmetrics\n",
            "  Downloading motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
            "\u001b[K     |████████████████████████████████| 161 kB 69.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (21.3)\n",
            "Requirement already satisfied: pandas<=1.3.5 in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (1.3.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (2.0.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (1.0.2)\n",
            "Requirement already satisfied: scipy<=1.7.3 in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (1.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (0.11.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (0.8.10)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mmtrack==1.0.0rc0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcls>=1.0.0rc0->mmtrack==1.0.0rc0) (1.21.6)\n",
            "Collecting rich\n",
            "  Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 68.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==1.0.0rc0) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas<=1.3.5->mmtrack==1.0.0rc0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas<=1.3.5->mmtrack==1.0.0rc0) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==1.0.0rc0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==1.0.0rc0) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmtrack==1.0.0rc0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmtrack==1.0.0rc0) (4.1.1)\n",
            "Collecting xmltodict>=0.12.0\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich->mmcls>=1.0.0rc0->mmtrack==1.0.0rc0) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mmtrack==1.0.0rc0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->mmtrack==1.0.0rc0) (3.1.0)\n",
            "Building wheels for collected packages: attributee, lap\n",
            "  Building wheel for attributee (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attributee: filename=attributee-0.1.7-py3-none-any.whl size=12696 sha256=73367345c942b1997e2a4c1def6389b0cadb090b21ab6015830b699e7fc69dfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/2d/85/6a50232dcc3c9814e3bd623402757e1759e57eb99aed930729\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1590201 sha256=cc56f5c066424629f72b58945914bbe5918fe55f9938f7e1a85c43d2c66c6c8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/0b/e3/ef9daf1b5547b56389e42c80c3100f1e6479bf5fd00fd9d6ba\n",
            "Successfully built attributee lap\n",
            "Installing collected packages: commonmark, xmltodict, rich, motmetrics, mmcls, lap, attributee, mmtrack\n",
            "  Running setup.py develop for mmtrack\n",
            "Successfully installed attributee-0.1.7 commonmark-0.9.1 lap-0.4.0 mmcls-1.0.0rc0 mmtrack-1.0.0rc0 motmetrics-1.2.5 rich-12.5.1 xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/JonathonLuiten/TrackEval.git\n",
            "  Cloning https://github.com/JonathonLuiten/TrackEval.git to /tmp/pip-req-build-2qhoo76v\n",
            "  Running command git clone -q https://github.com/JonathonLuiten/TrackEval.git /tmp/pip-req-build-2qhoo76v\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from trackeval==1.0.dev1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from trackeval==1.0.dev1) (1.7.3)\n",
            "Building wheels for collected packages: trackeval\n",
            "  Building wheel for trackeval (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trackeval: filename=trackeval-1.0.dev1-py3-none-any.whl size=121499 sha256=2eb58220d115d6d402ec919174b2a665dbcb05063c08547b32d3e4e7523bede6\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jvadplo0/wheels/f3/ca/38/409a5a8b4faf77d7e99a90462e20a4723c5b0f20fa12364aa7\n",
            "Successfully built trackeval\n",
            "Installing collected packages: trackeval\n",
            "Successfully installed trackeval-1.0.dev1\n"
          ]
        }
      ],
      "source": [
        "# install pytorch\n",
        "!pip install torch==1.10.0+cu111 torchvision==0.11.0+cu111 torchaudio==0.10.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install MMEngine\n",
        "!pip install mmengine\n",
        "\n",
        "# install MMCV\n",
        "!pip install 'mmcv>=2.0.0rc1' -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.10.0/index.html\n",
        "\n",
        "# install MMDetection\n",
        "!pip install 'mmdet>=3.0.0rc0'\n",
        "\n",
        "# clone the MMTracking repository\n",
        "!git clone -b 1.x https://github.com/open-mmlab/mmtracking.git\n",
        "%cd mmtracking\n",
        "\n",
        "# install MMTracking and its dependencies\n",
        "!pip install -r requirements/build.txt\n",
        "!pip install -e .\n",
        "# used to MOT evaluation\n",
        "!pip install git+https://github.com/JonathonLuiten/TrackEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03a4a583-78e7-40a1-a6ef-d80056989546",
        "outputId": "01ed3453-9d8b-4d91-e641-bdaf12259194"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('sys.platform', 'linux'),\n",
              "             ('Python', '3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]'),\n",
              "             ('CUDA available', True),\n",
              "             ('numpy_random_seed', 2147483648),\n",
              "             ('GPU 0', 'Tesla T4'),\n",
              "             ('CUDA_HOME', '/usr/local/cuda'),\n",
              "             ('NVCC', 'Cuda compilation tools, release 11.1, V11.1.105'),\n",
              "             ('GCC',\n",
              "              'x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0'),\n",
              "             ('PyTorch', '1.10.0+cu111'),\n",
              "             ('PyTorch compiling details',\n",
              "              'PyTorch built with:\\n  - GCC 7.3\\n  - C++ Version: 201402\\n  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX2\\n  - CUDA Runtime 11.1\\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\\n  - CuDNN 8.0.5\\n  - Magma 2.5.2\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \\n'),\n",
              "             ('TorchVision', '0.11.0+cu111'),\n",
              "             ('OpenCV', '4.6.0'),\n",
              "             ('MMEngine', '0.1.0')])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mmengine.utils.dl_utils import collect_env\n",
        "collect_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff6aea79-2ce9-4b1c-b3c4-3f92d1a4e34c",
        "outputId": "b7bced1c-800f-4314-9f2b-ad6c82ee1b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.10.0+cu111 True\n",
            "11.1\n",
            "GCC 7.3\n",
            "3.0.0rc0\n",
            "1.0.0rc0\n"
          ]
        }
      ],
      "source": [
        "# Check Pytorch installation\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "\n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())\n",
        "\n",
        "# Check MMDetection installation\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "\n",
        "# Check MMTracking installation\n",
        "import mmtrack\n",
        "print(mmtrack.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
      "metadata": {
        "id": "4d43b49c-320a-4b0f-baca-fb4bde0630ff",
        "tags": []
      },
      "source": [
        "## **Perform inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd7c8466-f057-455f-985a-71e5f22c36e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd7c8466-f057-455f-985a-71e5f22c36e4",
        "outputId": "3160be6e-2a84-49c5-f5e0-3dab58a607a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-06 08:05:44--  https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.89.140.71\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.89.140.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 282801031 (270M) [application/octet-stream]\n",
            "Saving to: ‘./checkpoints/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth’\n",
            "\n",
            "selsa_faster_rcnn_r 100%[===================>] 269.70M  7.75MB/s    in 31s     \n",
            "\n",
            "2022-09-06 08:06:16 (8.70 MB/s) - ‘./checkpoints/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth’ saved [282801031/282801031]\n",
            "\n",
            "--2022-09-06 08:06:16--  https://download.openmmlab.com/mmtracking/sot/siamese_rpn/siamese_rpn_r50_1x_lasot/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.89.140.71\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.89.140.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 216134418 (206M) [application/octet-stream]\n",
            "Saving to: ‘./checkpoints/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth’\n",
            "\n",
            "siamese_rpn_r50_1x_ 100%[===================>] 206.12M  7.60MB/s    in 24s     \n",
            "\n",
            "2022-09-06 08:06:41 (8.60 MB/s) - ‘./checkpoints/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth’ saved [216134418/216134418]\n",
            "\n",
            "--2022-09-06 08:06:41--  https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.89.140.71\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.89.140.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 232596799 (222M) [application/octet-stream]\n",
            "Saving to: ‘./checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth’\n",
            "\n",
            "masktrack_rcnn_r50_ 100%[===================>] 221.82M  9.09MB/s    in 25s     \n",
            "\n",
            "2022-09-06 08:07:07 (8.92 MB/s) - ‘./checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth’ saved [232596799/232596799]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# unset the proxy for downloading the pretrained models (optional)\n",
        "!unset https_proxy\n",
        "!unset http_proxy\n",
        "\n",
        "# download checkpoints\n",
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/vid/selsa/selsa_faster_rcnn_r50_dc5_1x_imagenetvid/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth -P ./checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/sot/siamese_rpn/siamese_rpn_r50_1x_lasot/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth -P ./checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmtracking/vis/masktrack_rcnn/masktrack_rcnn_r50_fpn_12e_youtubevis2019/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth -P ./checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "420dae4b-4426-405e-97fb-7823943b8ee8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "420dae4b-4426-405e-97fb-7823943b8ee8",
        "outputId": "74b49b29-5651-4b25-e866-b755c04c4797"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:08:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\n",
            "09/06 08:08:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: https://download.openmmlab.com/mmtracking/mot/faster_rcnn/faster-rcnn_r50_fpn_4e_mot17-half-64ee2ed4.pth\n",
            "09/06 08:08:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth\n",
            "09/06 08:08:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: https://download.openmmlab.com/mmtracking/mot/reid/tracktor_reid_r50_iter25245-a452f51f.pth\n",
            "09/06 08:08:27 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "missing keys in source state_dict: head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
            "\n",
            "[                                                  ] 0/8, elapsed: 0s, ETA:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmtracking/mmtrack/apis/inference.py:90: UserWarning: dataset_meta or class names are missed, use None by default.\n",
            "  warnings.warn('dataset_meta or class names are missed, '\n",
            "/usr/local/lib/python3.7/dist-packages/mmengine/visualization/visualizer.py:170: UserWarning: `Visualizer` backend is not initialized because save_dir is None.\n",
            "  warnings.warn('`Visualizer` backend is not initialized '\n",
            "/usr/local/lib/python3.7/dist-packages/mmengine/visualization/visualizer.py:709: UserWarning: Warning: The bbox is out of bounds, the drawn bbox may not be in the image\n",
            "  ' the drawn bbox may not be in the image', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/mmengine/visualization/visualizer.py:779: UserWarning: Warning: The polygon is out of bounds, the drawn polygon may not be in the image\n",
            "  ' the drawn polygon may not be in the image', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/mmengine/visualization/visualizer.py:469: UserWarning: Warning: The text is out of bounds, the drawn text may not be in the image\n",
            "  ' the drawn text may not be in the image', UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1.1 task/s, elapsed: 7s, ETA:     0s\n",
            " making the output video at ./demo/mot.mp4 with a FPS of 3.0\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 10.7 task/s, elapsed: 1s, ETA:     0s\n"
          ]
        }
      ],
      "source": [
        "# run mot demo\n",
        "import mmcv\n",
        "import mmengine\n",
        "import tempfile\n",
        "from mmtrack.apis import inference_mot, init_model\n",
        "from mmtrack.utils import register_all_modules\n",
        "from mmtrack.registry import VISUALIZERS\n",
        "\n",
        "register_all_modules(init_default_scope=True)\n",
        "mot_config = './configs/mot/deepsort/deepsort_faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval.py'\n",
        "input_video = './demo/demo.mp4'\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "# build the model from a config file\n",
        "mot_model = init_model(mot_config, device='cuda:0')\n",
        "\n",
        "# build the visualizer. Different name for creating different visualizer instance\n",
        "mot_model.cfg.visualizer.name = 'mot_visualizer'\n",
        "visualizer = VISUALIZERS.build(mot_model.cfg.visualizer)\n",
        "visualizer.dataset_meta = mot_model.dataset_meta\n",
        "\n",
        "prog_bar = mmengine.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "\n",
        "# test and show/save the images\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_mot(mot_model, img, frame_id=i)\n",
        "    visualizer.add_datasample(\n",
        "            'mot',\n",
        "            img[..., ::-1],\n",
        "            data_sample=result,\n",
        "            show=False,\n",
        "            out_file=f'{out_path}/{i:06d}.jpg',\n",
        "            wait_time=float(1 / int(imgs.fps)),\n",
        "            step=i)\n",
        "    prog_bar.update()\n",
        "\n",
        "output = './demo/mot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d4a97033-b779-4169-84c9-781c58840ae5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309,
          "referenced_widgets": [
            "a3fc7d320ed3417d833db4e9db0fce5c",
            "4eb851325f4b4cab82b8cbd979237520",
            "9f2fb13e136642728fbc97c8d7390118",
            "33267c31afd64c58b153a357aaa4569b",
            "98f236bb20444b919f136766394978ff",
            "ec62bc9001d349e696b8d82942e5b8c4",
            "b55031500bb345b58d0676c47e3c7843",
            "dd2d50cb741b4a79a13f0bf4a2b2242b",
            "9c5adcbe51ef438db298bff6a09c2065",
            "936d523d65254c10a9c64033283ca0f9",
            "4ea9a77bcea840e686d3525d4ef86cc8"
          ]
        },
        "id": "d4a97033-b779-4169-84c9-781c58840ae5",
        "outputId": "76592f9f-93ff-4ce9-dd03-9839fca4f2f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:09:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n",
            "09/06 08:09:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_fpn_1x_coco/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\" to /root/.cache/torch/hub/checkpoints/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3fc7d320ed3417d833db4e9db0fce5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:09:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([41, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([41]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([160, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([160]).\n",
            "size mismatch for roi_head.mask_head.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([40, 256, 1, 1]).\n",
            "size mismatch for roi_head.mask_head.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([40]).\n",
            "local loads checkpoint from path: ./checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1.1 task/s, elapsed: 7s, ETA:     0s\n",
            " making the output video at ./demo/vis.mp4 with a FPS of 3.0\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 10.8 task/s, elapsed: 1s, ETA:     0s\n"
          ]
        }
      ],
      "source": [
        "# run vis demo\n",
        "from mmtrack.apis import inference_mot\n",
        "vis_config = './configs/vis/masktrack_rcnn/masktrack-rcnn_mask-rcnn_r50_fpn_8xb1-12e_youtubevis2019.py'\n",
        "vis_checkpoint = './checkpoints/masktrack_rcnn_r50_fpn_12e_youtubevis2019_20211022_194830-6ca6b91e.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "vis_model = init_model(vis_config, vis_checkpoint, device='cuda:0')\n",
        "\n",
        "# build the visualizer. Different name for creating different visualizer instance\n",
        "vis_model.cfg.visualizer.name = 'vis_visualizer'\n",
        "visualizer = VISUALIZERS.build(vis_model.cfg.visualizer)\n",
        "visualizer.dataset_meta = vis_model.dataset_meta\n",
        "\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmengine.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_mot(vis_model, img, frame_id=i)\n",
        "    visualizer.add_datasample(\n",
        "            'vis',\n",
        "            img[..., ::-1],\n",
        "            data_sample=result,\n",
        "            show=False,\n",
        "            out_file=f'{out_path}/{i:06d}.jpg',\n",
        "            wait_time=float(1 / int(imgs.fps)),\n",
        "            step=i)\n",
        "    prog_bar.update()\n",
        "output = './demo/vis.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "abd0863b-933c-42d1-8442-70565d1b4b55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "d8911837396446c19d76bc22c5be63e2",
            "4679ff15b0db45fb9931757e0328d296",
            "64e629d4b1c74d2ab6c9ddc52ff4a2a9",
            "e00476c38c4d473191eeed5d6c42ecce",
            "a5c4355973c342acbae02ff5c32a677f",
            "5d7f321bb1fe4f32b3c1733a846ef8f5",
            "dc309139c6764cefa17ef542ebb36d3e",
            "3a09540c2a4247debd7c35b384e7ebed",
            "20b5b5e82f5548c98037ee236732ccfe",
            "4ebcc9b78ac64aedb146685a2437612c",
            "3d25971bbb3444b797b0faac0a934ffb"
          ]
        },
        "id": "abd0863b-933c-42d1-8442-70565d1b4b55",
        "outputId": "ba9acbe5-1488-4992-9916-36aff7bd4622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:09:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: torchvision://resnet50\n",
            "09/06 08:09:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - torchvision loads checkpoint from path: torchvision://resnet50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8911837396446c19d76bc22c5be63e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:09:34 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: fc.weight, fc.bias\n",
            "\n",
            "local loads checkpoint from path: ./checkpoints/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1.1 task/s, elapsed: 7s, ETA:     0s\n",
            " making the output video at ./demo/vid.mp4 with a FPS of 3.0\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 11.1 task/s, elapsed: 1s, ETA:     0s\n"
          ]
        }
      ],
      "source": [
        "# run vid demo\n",
        "from mmtrack.apis import inference_vid\n",
        "vid_config = './configs/vid/selsa/selsa_faster-rcnn_r50-dc5_8xb1-7e_imagenetvid.py'\n",
        "vid_checkpoint = './checkpoints/selsa_faster_rcnn_r50_dc5_1x_imagenetvid_20201227_204835-2f5a4952.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "vid_model = init_model(vid_config, vid_checkpoint, device='cuda:0')\n",
        "\n",
        "# build the visualizer. Different name for creating different visualizer instance\n",
        "vid_model.cfg.visualizer.name = 'vid_visualizer'\n",
        "visualizer = VISUALIZERS.build(vid_model.cfg.visualizer)\n",
        "visualizer.dataset_meta = vid_model.dataset_meta\n",
        "\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmengine.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_vid(vid_model, img, frame_id=i)\n",
        "    visualizer.add_datasample(\n",
        "            'vid',\n",
        "            img[..., ::-1],\n",
        "            data_sample=result,\n",
        "            show=False,\n",
        "            out_file=f'{out_path}/{i:06d}.jpg',\n",
        "            wait_time=float(1 / int(imgs.fps)),\n",
        "            step=i)\n",
        "    prog_bar.update()\n",
        "output = './demo/vid.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0189f86a-b216-4f63-a58a-97e40e326869",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "2db8224b7bb849c0a3c8a281bb57eb22",
            "b811cd2dd72040fe86cdc5238b522d06",
            "378b791183a24c558b2ce4afc1fe8a57",
            "9f46a04413cf4cce9f56a710aebe1424",
            "fb5e2db40e004e21a852c9f28740615c",
            "40b5616f3b3741d68210206a1d852418",
            "482683c5f93f41108ef0added3850519",
            "3942fdab3efa47e98ef1398b27eade57",
            "357be7f73b2848f89efe394758edc839",
            "b704c75bb577455dbac176c728b5540b",
            "e34931d882f44879aee48bfd46d62dce"
          ]
        },
        "id": "0189f86a-b216-4f63-a58a-97e40e326869",
        "outputId": "3160aaa9-20cf-45d6-e78d-ff4ffdb08bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:09:44 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmtracking/pretrained_weights/sot_resnet50.model\n",
            "09/06 08:09:44 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: https://download.openmmlab.com/mmtracking/pretrained_weights/sot_resnet50.model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.openmmlab.com/mmtracking/pretrained_weights/sot_resnet50.model\" to /root/.cache/torch/hub/checkpoints/sot_resnet50.model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2db8224b7bb849c0a3c8a281bb57eb22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/174M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "local loads checkpoint from path: ./checkpoints/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth\n",
            "[                                                  ] 0/8, elapsed: 0s, ETA:"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/mmtracking/mmtrack/apis/inference.py:90: UserWarning: dataset_meta or class names are missed, use None by default.\n",
            "  warnings.warn('dataset_meta or class names are missed, '\n",
            "/usr/local/lib/python3.7/dist-packages/mmengine/visualization/visualizer.py:170: UserWarning: `Visualizer` backend is not initialized because save_dir is None.\n",
            "  warnings.warn('`Visualizer` backend is not initialized '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 1.6 task/s, elapsed: 5s, ETA:     0s\n",
            " making the output video at ./demo/sot.mp4 with a FPS of 3.0\n",
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 8/8, 11.0 task/s, elapsed: 1s, ETA:     0s\n"
          ]
        }
      ],
      "source": [
        "# run sot demo\n",
        "from mmtrack.apis import inference_sot\n",
        "sot_config = './configs/sot/siamese_rpn/siamese-rpn_r50_8xb28-20e_imagenetvid-imagenetdet-coco_test-lasot.py'\n",
        "sot_checkpoint = './checkpoints/siamese_rpn_r50_1x_lasot_20211203_151612-da4b3c66.pth'\n",
        "# build the model from a config file and a checkpoint file\n",
        "sot_model = init_model(sot_config, sot_checkpoint, device='cuda:0')\n",
        "\n",
        "# build the visualizer. Different name for creating different visualizer instance\n",
        "sot_model.cfg.visualizer.name = 'sot_visualizer'\n",
        "visualizer = VISUALIZERS.build(sot_model.cfg.visualizer)\n",
        "visualizer.dataset_meta = sot_model.dataset_meta\n",
        "\n",
        "init_bbox = [371, 411, 450, 646]\n",
        "imgs = mmcv.VideoReader(input_video)\n",
        "prog_bar = mmengine.ProgressBar(len(imgs))\n",
        "out_dir = tempfile.TemporaryDirectory()\n",
        "out_path = out_dir.name\n",
        "for i, img in enumerate(imgs):\n",
        "    result = inference_sot(sot_model, img, init_bbox, frame_id=i)\n",
        "    visualizer.add_datasample(\n",
        "            'vid',\n",
        "            img[..., ::-1],\n",
        "            data_sample=result,\n",
        "            show=False,\n",
        "            out_file=f'{out_path}/{i:06d}.jpg',\n",
        "            wait_time=float(1 / int(imgs.fps)),\n",
        "            step=i)\n",
        "    prog_bar.update()\n",
        "output = './demo/sot.mp4'\n",
        "print(f'\\n making the output video at {output} with a FPS of {imgs.fps}')\n",
        "mmcv.frames2video(out_path, output, fps=imgs.fps, fourcc='mp4v')\n",
        "out_dir.cleanup()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
      "metadata": {
        "id": "500ff07b-9664-4429-9e3f-e97dd4fa1c29",
        "tags": []
      },
      "source": [
        "## **Train a MOT model with a toy dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
      "metadata": {
        "id": "e7bd4f44-447a-49a5-8c9c-cf160691bda5",
        "tags": []
      },
      "source": [
        "### **Prepare dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a91a55bd-14be-46bf-aa18-5e30d9abe5b7",
        "outputId": "837e0474-91fd-4090-f2e1-9017d2f6a389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-06 08:10:13--  https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.89.140.71\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.89.140.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 344566302 (329M) [application/zip]\n",
            "Saving to: ‘./data/MOT17_tiny.zip’\n",
            "\n",
            "MOT17_tiny.zip      100%[===================>] 328.60M  8.43MB/s    in 38s     \n",
            "\n",
            "2022-09-06 08:10:52 (8.63 MB/s) - ‘./data/MOT17_tiny.zip’ saved [344566302/344566302]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget https://download.openmmlab.com/mmtracking/data/MOT17_tiny.zip -P ./data\n",
        "!unzip -q ./data/MOT17_tiny.zip -d ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0db0d5f-b192-48ee-b145-149f33ad3685",
        "outputId": "8cad1091-09cf-4c97-9992-74af7d480dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Converting train set to COCO format\n",
            "100% 2/2 [00:00<00:00,  2.09it/s]\n",
            "train has 224 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/train_cocoformat.json and ./data/MOT17_tiny/annotations/train_detections.pkl\n",
            "Converting test set to COCO format\n",
            "0it [00:00, ?it/s]\n",
            "test has 0 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/test_cocoformat.json and ./data/MOT17_tiny/annotations/test_detections.pkl\n",
            "Converting half-train set to COCO format\n",
            "100% 2/2 [00:01<00:00,  1.01it/s]\n",
            "half-train has 182 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/half-train_cocoformat.json and ./data/MOT17_tiny/annotations/half-train_detections.pkl\n",
            "Converting half-val set to COCO format\n",
            "100% 2/2 [00:02<00:00,  1.01s/it]\n",
            "half-val has 201 instances.\n",
            "Done! Saved as ./data/MOT17_tiny/annotations/half-val_cocoformat.json and ./data/MOT17_tiny/annotations/half-val_detections.pkl\n",
            "100% 2/2 [09:35<00:00, 287.68s/it]\n"
          ]
        }
      ],
      "source": [
        "# convert the dataset to coco format\n",
        "!python ./tools/dataset_converters/mot/mot2coco.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/annotations --split-train --convert-det\n",
        "# crop pedestrian patches from the original dataset for training reid model. It may take a few minutes.\n",
        "!rm -rf ./data/MOT17_tiny/reid\n",
        "!python ./tools/dataset_converters/mot/mot2reid.py -i ./data/MOT17_tiny/ -o ./data/MOT17_tiny/reid --val-split 0.9 --vis-threshold 0.8"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
      "metadata": {
        "id": "ae887970-7382-4bd0-a739-6b07e6dded6f",
        "tags": []
      },
      "source": [
        "### **Train a detector for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce04095-8586-45c5-a556-40c51d08b2cb",
        "outputId": "407e272f-b1fe-4fb2-9265-55af95525335"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "dataset_type = 'mmdet.CocoDataset'\n",
            "data_root = 'data/MOT17_tiny/'\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=(1088, 1088),\n",
            "        ratio_range=(0.8, 1.2),\n",
            "        keep_ratio=True,\n",
            "        clip_object_border=False),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(type='PackDetInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor'))\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    batch_sampler=dict(type='mmdet.AspectRatioBatchSampler'),\n",
            "    dataset=dict(\n",
            "        type='mmdet.CocoDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        _scope_='mmdet',\n",
            "        ann_file='annotations/half-train_cocoformat.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        metainfo=dict(CLASSES=('pedestrian', )),\n",
            "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=(1088, 1088),\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                clip_object_border=False),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='RandomCrop',\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(type='PackDetInputs')\n",
            "        ]))\n",
            "val_dataloader = None\n",
            "test_dataloader = None\n",
            "val_evaluator = None\n",
            "test_evaluator = None\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='mmdet.DetLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='mot_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "model = dict(\n",
            "    data_preprocessor=dict(\n",
            "        type='DetDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        bgr_to_rgb=True,\n",
            "        pad_size_divisor=32),\n",
            "    type='FasterRCNN',\n",
            "    _scope_='mmdet',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "            clip_border=False),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=1,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                clip_border=False),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)),\n",
            "    init_cfg=dict(\n",
            "        type='Pretrained',\n",
            "        checkpoint=\n",
            "        'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
            "    ))\n",
            "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=4, val_interval=1)\n",
            "val_cfg = None\n",
            "test_cfg = None\n",
            "param_scheduler = [\n",
            "    dict(type='LinearLR', start_factor=0.01, by_epoch=False, begin=0, end=100),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=4,\n",
            "        by_epoch=True,\n",
            "        milestones=[3],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    optimizer=dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001))\n",
            "work_dir = './tutorial_exps/detector'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmengine\n",
        "from mmengine.runner import set_random_seed\n",
        "cfg = mmengine.Config.fromfile('./configs/det/faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval.py')\n",
        "cfg.data_root = 'data/MOT17_tiny/'\n",
        "cfg.train_dataloader.dataset.data_root = 'data/MOT17_tiny/'\n",
        "cfg.test_dataloader = cfg.test_cfg = cfg.test_evaluator = None\n",
        "cfg.val_dataloader = cfg.val_cfg = cfg.val_evaluator = None\n",
        "# different name for creating different visualizer instance\n",
        "cfg.visualizer.name = 'mot_visualizer'\n",
        "\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/detector'\n",
        "cfg.randomness = dict(seed=0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4757d999925e44748b3b4b8476ff7069",
            "64133dab9fa94eb9ad7819da4740a90f",
            "34b3be1af1704bd4a1a25992ff3a2c33",
            "1a722030c2344bf6a5ba1941c9e056de",
            "e0b78a16c9d8488eb6f2b78788bc1987",
            "36f603cf7dab445ab6120b805799c1d0",
            "f572376e2dbb437c95e1f62820d6f0d3",
            "9c5e87a7ba0f4b8395a3fd0027508930",
            "a83c0a2e5ee8432d9ecb05468194f3ed",
            "c1a6f0f21a864752bb77a435e5633c5f",
            "f4510cc71cf54df785fbe760b7dfc32c"
          ]
        },
        "id": "889b4255-50be-4da3-85c4-dcd19c8111ac",
        "outputId": "b9fb7a8b-ef72-4735-99a8-48e721f64130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:48:30 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.1, V11.1.105\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "    PyTorch: 1.10.0+cu111\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "    TorchVision: 0.11.0+cu111\n",
            "    OpenCV: 4.6.0\n",
            "    MMEngine: 0.1.0\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 0\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/06 08:48:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Config:\n",
            "dataset_type = 'mmdet.CocoDataset'\n",
            "data_root = 'data/MOT17_tiny/'\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='LoadAnnotations', with_bbox=True),\n",
            "    dict(\n",
            "        type='RandomResize',\n",
            "        scale=(1088, 1088),\n",
            "        ratio_range=(0.8, 1.2),\n",
            "        keep_ratio=True,\n",
            "        clip_object_border=False),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(type='RandomCrop', crop_size=(1088, 1088), bbox_clip_border=False),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(type='PackDetInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "    dict(\n",
            "        type='PackDetInputs',\n",
            "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
            "                   'scale_factor'))\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=2,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    batch_sampler=dict(type='mmdet.AspectRatioBatchSampler'),\n",
            "    dataset=dict(\n",
            "        type='mmdet.CocoDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        _scope_='mmdet',\n",
            "        ann_file='annotations/half-train_cocoformat.json',\n",
            "        data_prefix=dict(img='train/'),\n",
            "        metainfo=dict(CLASSES=('pedestrian', )),\n",
            "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(type='LoadAnnotations', with_bbox=True),\n",
            "            dict(\n",
            "                type='RandomResize',\n",
            "                scale=(1088, 1088),\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                clip_object_border=False),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='RandomCrop',\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(type='PackDetInputs')\n",
            "        ]))\n",
            "val_dataloader = None\n",
            "test_dataloader = None\n",
            "val_evaluator = None\n",
            "test_evaluator = None\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='mmdet.DetVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='mmdet.DetLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='mot_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "model = dict(\n",
            "    data_preprocessor=dict(\n",
            "        type='DetDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        bgr_to_rgb=True,\n",
            "        pad_size_divisor=32),\n",
            "    type='FasterRCNN',\n",
            "    _scope_='mmdet',\n",
            "    backbone=dict(\n",
            "        type='ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        frozen_stages=1,\n",
            "        norm_cfg=dict(type='BN', requires_grad=True),\n",
            "        norm_eval=True,\n",
            "        style='pytorch',\n",
            "        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "    neck=dict(\n",
            "        type='FPN',\n",
            "        in_channels=[256, 512, 1024, 2048],\n",
            "        out_channels=256,\n",
            "        num_outs=5),\n",
            "    rpn_head=dict(\n",
            "        type='RPNHead',\n",
            "        in_channels=256,\n",
            "        feat_channels=256,\n",
            "        anchor_generator=dict(\n",
            "            type='AnchorGenerator',\n",
            "            scales=[8],\n",
            "            ratios=[0.5, 1.0, 2.0],\n",
            "            strides=[4, 8, 16, 32, 64]),\n",
            "        bbox_coder=dict(\n",
            "            type='DeltaXYWHBBoxCoder',\n",
            "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "            target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "            clip_border=False),\n",
            "        loss_cls=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "        loss_bbox=dict(\n",
            "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
            "    roi_head=dict(\n",
            "        type='StandardRoIHead',\n",
            "        bbox_roi_extractor=dict(\n",
            "            type='SingleRoIExtractor',\n",
            "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "            out_channels=256,\n",
            "            featmap_strides=[4, 8, 16, 32]),\n",
            "        bbox_head=dict(\n",
            "            type='Shared2FCBBoxHead',\n",
            "            in_channels=256,\n",
            "            fc_out_channels=1024,\n",
            "            roi_feat_size=7,\n",
            "            num_classes=1,\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                clip_border=False),\n",
            "            reg_class_agnostic=False,\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
            "            loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "    train_cfg=dict(\n",
            "        rpn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.7,\n",
            "                neg_iou_thr=0.3,\n",
            "                min_pos_iou=0.3,\n",
            "                match_low_quality=True,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=256,\n",
            "                pos_fraction=0.5,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=False),\n",
            "            allowed_border=-1,\n",
            "            pos_weight=-1,\n",
            "            debug=False),\n",
            "        rpn_proposal=dict(\n",
            "            nms_pre=2000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            assigner=dict(\n",
            "                type='MaxIoUAssigner',\n",
            "                pos_iou_thr=0.5,\n",
            "                neg_iou_thr=0.5,\n",
            "                min_pos_iou=0.5,\n",
            "                match_low_quality=False,\n",
            "                ignore_iof_thr=-1),\n",
            "            sampler=dict(\n",
            "                type='RandomSampler',\n",
            "                num=512,\n",
            "                pos_fraction=0.25,\n",
            "                neg_pos_ub=-1,\n",
            "                add_gt_as_proposals=True),\n",
            "            pos_weight=-1,\n",
            "            debug=False)),\n",
            "    test_cfg=dict(\n",
            "        rpn=dict(\n",
            "            nms_pre=1000,\n",
            "            max_per_img=1000,\n",
            "            nms=dict(type='nms', iou_threshold=0.7),\n",
            "            min_bbox_size=0),\n",
            "        rcnn=dict(\n",
            "            score_thr=0.05,\n",
            "            nms=dict(type='nms', iou_threshold=0.5),\n",
            "            max_per_img=100)),\n",
            "    init_cfg=dict(\n",
            "        type='Pretrained',\n",
            "        checkpoint=\n",
            "        'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'\n",
            "    ))\n",
            "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=4, val_interval=1)\n",
            "val_cfg = None\n",
            "test_cfg = None\n",
            "param_scheduler = [\n",
            "    dict(type='LinearLR', start_factor=0.01, by_epoch=False, begin=0, end=100),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=4,\n",
            "        by_epoch=True,\n",
            "        milestones=[3],\n",
            "        gamma=0.1)\n",
            "]\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    optimizer=dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001))\n",
            "work_dir = './tutorial_exps/detector'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "Result has been saved to /content/mmtracking/tutorial_exps/detector/modules_statistic_results.json\n",
            "09/06 08:48:32 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "loading annotations into memory...\n",
            "Done (t=0.54s)\n",
            "creating index...\n",
            "index created!\n",
            "09/06 08:48:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n",
            "09/06 08:48:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\" to /root/.cache/torch/hub/checkpoints/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4757d999925e44748b3b4b8476ff7069",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/160M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 08:48:53 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([2, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([4]).\n",
            "09/06 08:48:53 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to /content/mmtracking/tutorial_exps/detector by HardDiskBackend.\n",
            "09/06 08:49:17 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][50/414]  lr: 1.0000e-02  eta: 0:12:31  time: 0.4476  data_time: 0.0086  memory: 4097  loss_rpn_cls: 0.0432  loss_rpn_bbox: 0.1128  loss_cls: 0.3478  acc: 87.7930  loss_bbox: 0.2661  loss: 0.7698\n",
            "09/06 08:49:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][100/414]  lr: 2.0000e-02  eta: 0:12:03  time: 0.4664  data_time: 0.0077  memory: 4096  loss_rpn_cls: 0.0310  loss_rpn_bbox: 0.1023  loss_cls: 0.3020  acc: 85.7422  loss_bbox: 0.2093  loss: 0.6447\n",
            "09/06 08:50:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][150/414]  lr: 2.0000e-02  eta: 0:11:41  time: 0.4669  data_time: 0.0085  memory: 4097  loss_rpn_cls: 0.0210  loss_rpn_bbox: 0.0953  loss_cls: 0.3098  acc: 87.9883  loss_bbox: 0.2082  loss: 0.6343\n",
            "09/06 08:50:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][200/414]  lr: 2.0000e-02  eta: 0:11:20  time: 0.4539  data_time: 0.0089  memory: 4097  loss_rpn_cls: 0.0263  loss_rpn_bbox: 0.0771  loss_cls: 0.2932  acc: 84.3750  loss_bbox: 0.2172  loss: 0.6138\n",
            "09/06 08:50:50 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][250/414]  lr: 2.0000e-02  eta: 0:10:54  time: 0.4517  data_time: 0.0098  memory: 4097  loss_rpn_cls: 0.0162  loss_rpn_bbox: 0.0778  loss_cls: 0.2588  acc: 86.9141  loss_bbox: 0.1758  loss: 0.5286\n",
            "09/06 08:51:13 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][300/414]  lr: 2.0000e-02  eta: 0:10:33  time: 0.4759  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0133  loss_rpn_bbox: 0.0772  loss_cls: 0.2558  acc: 87.4023  loss_bbox: 0.1703  loss: 0.5165\n",
            "09/06 08:51:36 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][350/414]  lr: 2.0000e-02  eta: 0:10:07  time: 0.4605  data_time: 0.0085  memory: 4096  loss_rpn_cls: 0.0155  loss_rpn_bbox: 0.0722  loss_cls: 0.2608  acc: 90.4297  loss_bbox: 0.1860  loss: 0.5345\n",
            "09/06 08:51:59 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][400/414]  lr: 2.0000e-02  eta: 0:09:43  time: 0.4660  data_time: 0.0085  memory: 4097  loss_rpn_cls: 0.0159  loss_rpn_bbox: 0.0762  loss_cls: 0.2045  acc: 92.2852  loss_bbox: 0.1252  loss: 0.4218\n",
            "09/06 08:52:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval_20220906_084830\n",
            "09/06 08:52:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "09/06 08:52:32 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][50/414]  lr: 2.0000e-02  eta: 0:09:08  time: 0.4438  data_time: 0.0085  memory: 4097  loss_rpn_cls: 0.0117  loss_rpn_bbox: 0.0568  loss_cls: 0.2145  acc: 92.7734  loss_bbox: 0.1412  loss: 0.4241\n",
            "09/06 08:52:55 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][100/414]  lr: 2.0000e-02  eta: 0:08:47  time: 0.4764  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0128  loss_rpn_bbox: 0.0551  loss_cls: 0.2117  acc: 92.8711  loss_bbox: 0.1495  loss: 0.4291\n",
            "09/06 08:53:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][150/414]  lr: 2.0000e-02  eta: 0:08:24  time: 0.4226  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0185  loss_rpn_bbox: 0.0557  loss_cls: 0.2072  acc: 89.3555  loss_bbox: 0.1273  loss: 0.4087\n",
            "09/06 08:53:41 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][200/414]  lr: 2.0000e-02  eta: 0:08:00  time: 0.4544  data_time: 0.0081  memory: 4097  loss_rpn_cls: 0.0110  loss_rpn_bbox: 0.0498  loss_cls: 0.1904  acc: 90.1367  loss_bbox: 0.1130  loss: 0.3641\n",
            "09/06 08:54:04 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][250/414]  lr: 2.0000e-02  eta: 0:07:36  time: 0.4227  data_time: 0.0082  memory: 4097  loss_rpn_cls: 0.0146  loss_rpn_bbox: 0.0475  loss_cls: 0.2017  acc: 90.4297  loss_bbox: 0.1279  loss: 0.3917\n",
            "09/06 08:54:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][300/414]  lr: 2.0000e-02  eta: 0:07:13  time: 0.4572  data_time: 0.0083  memory: 4097  loss_rpn_cls: 0.0100  loss_rpn_bbox: 0.0637  loss_cls: 0.1965  acc: 93.2617  loss_bbox: 0.1399  loss: 0.4102\n",
            "09/06 08:54:50 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][350/414]  lr: 2.0000e-02  eta: 0:06:50  time: 0.4661  data_time: 0.0093  memory: 4097  loss_rpn_cls: 0.0096  loss_rpn_bbox: 0.0440  loss_cls: 0.1747  acc: 91.6016  loss_bbox: 0.1094  loss: 0.3377\n",
            "09/06 08:55:13 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][400/414]  lr: 2.0000e-02  eta: 0:06:27  time: 0.4538  data_time: 0.0085  memory: 4097  loss_rpn_cls: 0.0083  loss_rpn_bbox: 0.0413  loss_cls: 0.1579  acc: 94.7266  loss_bbox: 0.1079  loss: 0.3153\n",
            "09/06 08:55:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval_20220906_084830\n",
            "09/06 08:55:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
            "09/06 08:55:44 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][50/414]  lr: 2.0000e-02  eta: 0:05:56  time: 0.4519  data_time: 0.0089  memory: 4097  loss_rpn_cls: 0.0062  loss_rpn_bbox: 0.0405  loss_cls: 0.1676  acc: 91.6992  loss_bbox: 0.1083  loss: 0.3226\n",
            "09/06 08:56:08 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][100/414]  lr: 2.0000e-02  eta: 0:05:33  time: 0.4734  data_time: 0.0091  memory: 4097  loss_rpn_cls: 0.0049  loss_rpn_bbox: 0.0337  loss_cls: 0.1571  acc: 94.1406  loss_bbox: 0.0945  loss: 0.2903\n",
            "09/06 08:56:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][150/414]  lr: 2.0000e-02  eta: 0:05:10  time: 0.4527  data_time: 0.0087  memory: 4097  loss_rpn_cls: 0.0112  loss_rpn_bbox: 0.0406  loss_cls: 0.1630  acc: 93.9453  loss_bbox: 0.1075  loss: 0.3223\n",
            "09/06 08:56:41 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval_20220906_084830\n",
            "09/06 08:56:54 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][200/414]  lr: 2.0000e-02  eta: 0:04:48  time: 0.4468  data_time: 0.0086  memory: 4097  loss_rpn_cls: 0.0069  loss_rpn_bbox: 0.0554  loss_cls: 0.1763  acc: 90.3320  loss_bbox: 0.1082  loss: 0.3468\n",
            "09/06 08:57:17 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][250/414]  lr: 2.0000e-02  eta: 0:04:25  time: 0.4645  data_time: 0.0084  memory: 4097  loss_rpn_cls: 0.0079  loss_rpn_bbox: 0.0441  loss_cls: 0.1617  acc: 94.3359  loss_bbox: 0.1107  loss: 0.3244\n",
            "09/06 08:57:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][300/414]  lr: 2.0000e-02  eta: 0:04:02  time: 0.4733  data_time: 0.0089  memory: 4097  loss_rpn_cls: 0.0078  loss_rpn_bbox: 0.0374  loss_cls: 0.1390  acc: 95.5078  loss_bbox: 0.1000  loss: 0.2842\n",
            "09/06 08:58:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][350/414]  lr: 2.0000e-02  eta: 0:03:39  time: 0.4550  data_time: 0.0088  memory: 4097  loss_rpn_cls: 0.0071  loss_rpn_bbox: 0.0365  loss_cls: 0.1668  acc: 93.8477  loss_bbox: 0.1056  loss: 0.3161\n",
            "09/06 08:58:26 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [3][400/414]  lr: 2.0000e-02  eta: 0:03:16  time: 0.4494  data_time: 0.0080  memory: 4097  loss_rpn_cls: 0.0048  loss_rpn_bbox: 0.0341  loss_cls: 0.1349  acc: 95.3125  loss_bbox: 0.0942  loss: 0.2680\n",
            "09/06 08:58:32 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval_20220906_084830\n",
            "09/06 08:58:32 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "09/06 08:58:58 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][50/414]  lr: 2.0000e-03  eta: 0:02:46  time: 0.4481  data_time: 0.0088  memory: 4097  loss_rpn_cls: 0.0031  loss_rpn_bbox: 0.0288  loss_cls: 0.1293  acc: 96.3867  loss_bbox: 0.0897  loss: 0.2510\n",
            "09/06 08:59:22 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][100/414]  lr: 2.0000e-03  eta: 0:02:23  time: 0.4767  data_time: 0.0085  memory: 4097  loss_rpn_cls: 0.0048  loss_rpn_bbox: 0.0314  loss_cls: 0.1376  acc: 94.2383  loss_bbox: 0.1000  loss: 0.2737\n",
            "09/06 08:59:45 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][150/414]  lr: 2.0000e-03  eta: 0:02:01  time: 0.4850  data_time: 0.0098  memory: 4096  loss_rpn_cls: 0.0037  loss_rpn_bbox: 0.0232  loss_cls: 0.1152  acc: 92.9688  loss_bbox: 0.0722  loss: 0.2142\n",
            "09/06 09:00:08 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][200/414]  lr: 2.0000e-03  eta: 0:01:38  time: 0.4694  data_time: 0.0089  memory: 4097  loss_rpn_cls: 0.0054  loss_rpn_bbox: 0.0279  loss_cls: 0.1285  acc: 93.4570  loss_bbox: 0.0880  loss: 0.2497\n",
            "09/06 09:00:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][250/414]  lr: 2.0000e-03  eta: 0:01:15  time: 0.4595  data_time: 0.0084  memory: 4097  loss_rpn_cls: 0.0030  loss_rpn_bbox: 0.0255  loss_cls: 0.1147  acc: 95.4102  loss_bbox: 0.0822  loss: 0.2254\n",
            "09/06 09:00:54 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][300/414]  lr: 2.0000e-03  eta: 0:00:52  time: 0.4778  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0063  loss_rpn_bbox: 0.0279  loss_cls: 0.1356  acc: 93.7500  loss_bbox: 0.0900  loss: 0.2598\n",
            "09/06 09:01:17 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][350/414]  lr: 2.0000e-03  eta: 0:00:29  time: 0.4581  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0064  loss_rpn_bbox: 0.0233  loss_cls: 0.1073  acc: 96.5820  loss_bbox: 0.0767  loss: 0.2138\n",
            "09/06 09:01:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [4][400/414]  lr: 2.0000e-03  eta: 0:00:06  time: 0.4541  data_time: 0.0090  memory: 4097  loss_rpn_cls: 0.0037  loss_rpn_bbox: 0.0238  loss_cls: 0.1253  acc: 96.5820  loss_bbox: 0.0766  loss: 0.2293\n",
            "09/06 09:01:46 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval_20220906_084830\n",
            "09/06 09:01:46 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FasterRCNN(\n",
              "  (data_preprocessor): DetDataPreprocessor()\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n",
              "  (neck): FPN(\n",
              "    (lateral_convs): ModuleList(\n",
              "      (0): ConvModule(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ConvModule(\n",
              "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (2): ConvModule(\n",
              "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (3): ConvModule(\n",
              "        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (fpn_convs): ModuleList(\n",
              "      (0): ConvModule(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (1): ConvModule(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (2): ConvModule(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "      (3): ConvModule(\n",
              "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
              "  (rpn_head): RPNHead(\n",
              "    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
              "    (loss_bbox): SmoothL1Loss()\n",
              "    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
              "  (roi_head): StandardRoIHead(\n",
              "    (bbox_roi_extractor): SingleRoIExtractor(\n",
              "      (roi_layers): ModuleList(\n",
              "        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
              "        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
              "        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
              "        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n",
              "      )\n",
              "    )\n",
              "    (bbox_head): Shared2FCBBoxHead(\n",
              "      (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n",
              "      (loss_bbox): SmoothL1Loss()\n",
              "      (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n",
              "      (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n",
              "      (shared_convs): ModuleList()\n",
              "      (shared_fcs): ModuleList(\n",
              "        (0): Linear(in_features=12544, out_features=1024, bias=True)\n",
              "        (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      )\n",
              "      (cls_convs): ModuleList()\n",
              "      (cls_fcs): ModuleList()\n",
              "      (reg_convs): ModuleList()\n",
              "      (reg_fcs): ModuleList()\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
              "  )\n",
              ")\n",
              "init_cfg={'type': 'Pretrained', 'checkpoint': 'http://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_2x_coco/faster_rcnn_r50_fpn_2x_coco_bbox_mAP-0.384_20200504_210434-a5d8aa15.pth'}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmengine.utils import mkdir_or_exist\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
      "metadata": {
        "id": "7f747c1f-7944-49f2-b9fc-a51dc3f85857",
        "tags": []
      },
      "source": [
        "### **Train a ReID model for MOT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6705deeb-a9d7-42e2-9d52-b51b7b588d1f",
        "outputId": "a4f24af8-fc91-4459-f4c0-3f0ced62e0f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "dataset_type = 'ReIDDataset'\n",
            "data_root = 'data/MOT17/'\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=False,\n",
            "        transforms=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(\n",
            "                type='mmdet.Resize',\n",
            "                scale=(128, 256),\n",
            "                keep_ratio=False,\n",
            "                clip_object_border=False),\n",
            "            dict(type='RandomFlip', prob=0.5, direction='horizontal')\n",
            "        ]),\n",
            "    dict(type='PackReIDInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='mmdet.Resize', scale=(128, 256), keep_ratio=False),\n",
            "    dict(type='PackReIDInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='ReIDDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
            "        data_prefix=dict(img_path='reid/imgs'),\n",
            "        ann_file='reid/meta/train_9.txt',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='TransformBroadcaster',\n",
            "                share_random_params=False,\n",
            "                transforms=[\n",
            "                    dict(type='LoadImageFromFile', to_float32=True),\n",
            "                    dict(\n",
            "                        type='mmdet.Resize',\n",
            "                        scale=(128, 256),\n",
            "                        keep_ratio=False,\n",
            "                        clip_object_border=False),\n",
            "                    dict(type='RandomFlip', prob=0.5, direction='horizontal')\n",
            "                ]),\n",
            "            dict(type='PackReIDInputs')\n",
            "        ]))\n",
            "val_dataloader = None\n",
            "test_dataloader = None\n",
            "val_evaluator = None\n",
            "test_evaluator = None\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='TrackVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='TrackLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='mot_reid_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "model = dict(\n",
            "    type='BaseReID',\n",
            "    data_preprocessor=dict(\n",
            "        type='mmcls.ClsDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    backbone=dict(\n",
            "        type='mmcls.ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(3, ),\n",
            "        style='pytorch'),\n",
            "    neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "    head=dict(\n",
            "        type='LinearReIDHead',\n",
            "        num_fcs=1,\n",
            "        in_channels=2048,\n",
            "        fc_channels=1024,\n",
            "        out_channels=128,\n",
            "        num_classes=380,\n",
            "        loss_cls=dict(type='mmcls.CrossEntropyLoss', loss_weight=1.0),\n",
            "        loss_triplet=dict(type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "        norm_cfg=dict(type='BN1d'),\n",
            "        act_cfg=dict(type='ReLU')),\n",
            "    init_cfg=dict(\n",
            "        type='Pretrained',\n",
            "        checkpoint=\n",
            "        'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
            "    ))\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='LinearLR', start_factor=0.005, by_epoch=False, begin=0, end=200),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=2,\n",
            "        by_epoch=True,\n",
            "        milestones=[1],\n",
            "        gamma=0.1)\n",
            "]\n",
            "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=2, val_begin=3)\n",
            "val_cfg = None\n",
            "test_cfg = None\n",
            "work_dir = './tutorial_exps/reid'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmengine\n",
        "\n",
        "cfg = mmengine.Config.fromfile('./configs/reid/reid_r50_8xb32-6e_mot17train80_test-mot17val20.py')\n",
        "cfg.train_dataloader.dataset.data_root = 'data/MOT17_tiny/'\n",
        "cfg.train_dataloader.dataset.ann_file = 'reid/meta/train_9.txt'\n",
        "cfg.test_dataloader = cfg.test_cfg = cfg.test_evaluator = None\n",
        "cfg.val_dataloader = cfg.val_cfg = cfg.val_evaluator = None\n",
        "cfg.visualizer.name = 'mot_reid_visualizer'\n",
        "\n",
        "# learning policy\n",
        "cfg.param_scheduler = [\n",
        "    dict(\n",
        "        type='LinearLR',\n",
        "        start_factor=1.0 / 200,\n",
        "        by_epoch=False,\n",
        "        begin=0,\n",
        "        end=200),\n",
        "    dict(\n",
        "        type='MultiStepLR',\n",
        "        begin=0,\n",
        "        end=2,\n",
        "        by_epoch=True,\n",
        "        milestones=[1],\n",
        "        gamma=0.1)\n",
        "]\n",
        "cfg.train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=2, val_begin=3)\n",
        "\n",
        "cfg.work_dir = './tutorial_exps/reid'\n",
        "cfg.randomness = dict(seed=0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "12f2b54e-7e5f-4d95-9e27-528115717e03",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "34594c7fd26c4f61af5e4ec5b34b6b02",
            "8727613cf45f4cd4a79557afd1973632",
            "28ef474b2c7c466baa81c1196f8e7505",
            "7b268f5a3b334d2c89ae8d43fda6eb53",
            "9d467daaa30e44288dd49152948db460",
            "9793eaee82db45beaddf9e80cab6d0a1",
            "e75e2e078b4246a9984fa0841de27a15",
            "504570ec6de24f40b824fb8eacc65447",
            "b9470c130a69411b8be481f4aa045d26",
            "0b4dd8ace9b5467e9e7c0214df6df1a9",
            "e495e81fecf844a4ae4a15ca9cb0329c"
          ]
        },
        "id": "12f2b54e-7e5f-4d95-9e27-528115717e03",
        "outputId": "c9952c03-33c9-450b-d325-a526821a93ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 09:16:26 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.1, V11.1.105\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "    PyTorch: 1.10.0+cu111\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "    TorchVision: 0.11.0+cu111\n",
            "    OpenCV: 4.6.0\n",
            "    MMEngine: 0.1.0\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 0\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/06 09:16:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Config:\n",
            "dataset_type = 'ReIDDataset'\n",
            "data_root = 'data/MOT17/'\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=False,\n",
            "        transforms=[\n",
            "            dict(type='LoadImageFromFile', to_float32=True),\n",
            "            dict(\n",
            "                type='mmdet.Resize',\n",
            "                scale=(128, 256),\n",
            "                keep_ratio=False,\n",
            "                clip_object_border=False),\n",
            "            dict(type='RandomFlip', prob=0.5, direction='horizontal')\n",
            "        ]),\n",
            "    dict(type='PackReIDInputs')\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile', to_float32=True),\n",
            "    dict(type='mmdet.Resize', scale=(128, 256), keep_ratio=False),\n",
            "    dict(type='PackReIDInputs')\n",
            "]\n",
            "train_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
            "    dataset=dict(\n",
            "        type='ReIDDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        triplet_sampler=dict(num_ids=8, ins_per_id=4),\n",
            "        data_prefix=dict(img_path='reid/imgs'),\n",
            "        ann_file='reid/meta/train_9.txt',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                type='TransformBroadcaster',\n",
            "                share_random_params=False,\n",
            "                transforms=[\n",
            "                    dict(type='LoadImageFromFile', to_float32=True),\n",
            "                    dict(\n",
            "                        type='mmdet.Resize',\n",
            "                        scale=(128, 256),\n",
            "                        keep_ratio=False,\n",
            "                        clip_object_border=False),\n",
            "                    dict(type='RandomFlip', prob=0.5, direction='horizontal')\n",
            "                ]),\n",
            "            dict(type='PackReIDInputs')\n",
            "        ]))\n",
            "val_dataloader = None\n",
            "test_dataloader = None\n",
            "val_evaluator = None\n",
            "test_evaluator = None\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='TrackVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='TrackLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='mot_reid_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "model = dict(\n",
            "    type='BaseReID',\n",
            "    data_preprocessor=dict(\n",
            "        type='mmcls.ClsDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    backbone=dict(\n",
            "        type='mmcls.ResNet',\n",
            "        depth=50,\n",
            "        num_stages=4,\n",
            "        out_indices=(3, ),\n",
            "        style='pytorch'),\n",
            "    neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "    head=dict(\n",
            "        type='LinearReIDHead',\n",
            "        num_fcs=1,\n",
            "        in_channels=2048,\n",
            "        fc_channels=1024,\n",
            "        out_channels=128,\n",
            "        num_classes=380,\n",
            "        loss_cls=dict(type='mmcls.CrossEntropyLoss', loss_weight=1.0),\n",
            "        loss_triplet=dict(type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "        norm_cfg=dict(type='BN1d'),\n",
            "        act_cfg=dict(type='ReLU')),\n",
            "    init_cfg=dict(\n",
            "        type='Pretrained',\n",
            "        checkpoint=\n",
            "        'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'\n",
            "    ))\n",
            "optim_wrapper = dict(\n",
            "    type='OptimWrapper',\n",
            "    clip_grad=None,\n",
            "    optimizer=dict(type='SGD', lr=0.1, momentum=0.9, weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        type='LinearLR', start_factor=0.005, by_epoch=False, begin=0, end=200),\n",
            "    dict(\n",
            "        type='MultiStepLR',\n",
            "        begin=0,\n",
            "        end=2,\n",
            "        by_epoch=True,\n",
            "        milestones=[1],\n",
            "        gamma=0.1)\n",
            "]\n",
            "train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=2, val_begin=3)\n",
            "val_cfg = None\n",
            "test_cfg = None\n",
            "work_dir = './tutorial_exps/reid'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "Result has been saved to /content/mmtracking/tutorial_exps/reid/modules_statistic_results.json\n",
            "09/06 09:16:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/06 09:16:29 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n",
            "09/06 09:16:29 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - http loads checkpoint from path: https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth\" to /root/.cache/torch/hub/checkpoints/resnet50_batch256_imagenet_20200708-cfb998bf.pth\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34594c7fd26c4f61af5e4ec5b34b6b02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0.00/97.7M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 09:16:40 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: head.fc.weight, head.fc.bias\n",
            "\n",
            "missing keys in source state_dict: head.fcs.0.fc.weight, head.fcs.0.fc.bias, head.fcs.0.bn.weight, head.fcs.0.bn.bias, head.fcs.0.bn.running_mean, head.fcs.0.bn.running_var, head.fc_out.weight, head.fc_out.bias, head.bn.weight, head.bn.bias, head.bn.running_mean, head.bn.running_var, head.classifier.weight, head.classifier.bias\n",
            "\n",
            "09/06 09:16:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Checkpoints will be saved to /content/mmtracking/tutorial_exps/reid by HardDiskBackend.\n",
            "09/06 09:16:56 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][50/1576]  lr: 2.5000e-02  eta: 0:16:34  time: 0.3139  data_time: 0.0053  memory: 4097  triplet_loss: 0.0000  ce_loss: 0.0004  accuracy_top-1: 100.0000  loss: 0.0006\n",
            "09/06 09:17:12 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][100/1576]  lr: 5.0000e-02  eta: 0:16:09  time: 0.3246  data_time: 0.0059  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:17:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][150/1576]  lr: 7.5000e-02  eta: 0:15:49  time: 0.3163  data_time: 0.0052  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:17:44 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][200/1576]  lr: 1.0000e-01  eta: 0:15:37  time: 0.3179  data_time: 0.0054  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:18:00 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][250/1576]  lr: 1.0000e-01  eta: 0:15:23  time: 0.3169  data_time: 0.0057  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:18:15 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][300/1576]  lr: 1.0000e-01  eta: 0:15:06  time: 0.3144  data_time: 0.0054  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:18:31 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][350/1576]  lr: 1.0000e-01  eta: 0:14:49  time: 0.3130  data_time: 0.0055  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:18:47 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][400/1576]  lr: 1.0000e-01  eta: 0:14:33  time: 0.3278  data_time: 0.0051  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:19:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][450/1576]  lr: 1.0000e-01  eta: 0:14:17  time: 0.3153  data_time: 0.0066  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:19:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][500/1576]  lr: 1.0000e-01  eta: 0:14:02  time: 0.3160  data_time: 0.0062  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:19:35 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][550/1576]  lr: 1.0000e-01  eta: 0:13:48  time: 0.3330  data_time: 0.0112  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:19:51 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][600/1576]  lr: 1.0000e-01  eta: 0:13:32  time: 0.3242  data_time: 0.0061  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:20:07 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][650/1576]  lr: 1.0000e-01  eta: 0:13:16  time: 0.3155  data_time: 0.0070  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:20:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][700/1576]  lr: 1.0000e-01  eta: 0:13:00  time: 0.3125  data_time: 0.0067  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:20:39 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][750/1576]  lr: 1.0000e-01  eta: 0:12:43  time: 0.3165  data_time: 0.0063  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:20:54 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][800/1576]  lr: 1.0000e-01  eta: 0:12:27  time: 0.3162  data_time: 0.0056  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:21:10 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][850/1576]  lr: 1.0000e-01  eta: 0:12:11  time: 0.3189  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:21:26 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][900/1576]  lr: 1.0000e-01  eta: 0:11:56  time: 0.3293  data_time: 0.0081  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:21:42 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][950/1576]  lr: 1.0000e-01  eta: 0:11:40  time: 0.3159  data_time: 0.0067  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:21:58 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: reid_r50_8xb32-6e_mot17train80_test-mot17val20_20220906_091626\n",
            "09/06 09:21:58 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1000/1576]  lr: 1.0000e-01  eta: 0:11:24  time: 0.3142  data_time: 0.0055  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:22:14 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1050/1576]  lr: 1.0000e-01  eta: 0:11:08  time: 0.3153  data_time: 0.0052  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0001\n",
            "09/06 09:22:30 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1100/1576]  lr: 1.0000e-01  eta: 0:10:52  time: 0.3137  data_time: 0.0059  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0001  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:22:46 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1150/1576]  lr: 1.0000e-01  eta: 0:10:36  time: 0.3151  data_time: 0.0068  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:23:02 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1200/1576]  lr: 1.0000e-01  eta: 0:10:20  time: 0.3174  data_time: 0.0059  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:23:18 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1250/1576]  lr: 1.0000e-01  eta: 0:10:04  time: 0.3185  data_time: 0.0065  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:23:33 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1300/1576]  lr: 1.0000e-01  eta: 0:09:48  time: 0.3165  data_time: 0.0061  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:23:50 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1350/1576]  lr: 1.0000e-01  eta: 0:09:33  time: 0.3163  data_time: 0.0066  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:24:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1400/1576]  lr: 1.0000e-01  eta: 0:09:17  time: 0.3148  data_time: 0.0064  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:24:21 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1450/1576]  lr: 1.0000e-01  eta: 0:09:01  time: 0.3157  data_time: 0.0061  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:24:37 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1500/1576]  lr: 1.0000e-01  eta: 0:08:45  time: 0.3160  data_time: 0.0067  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:24:53 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [1][1550/1576]  lr: 1.0000e-01  eta: 0:08:29  time: 0.3164  data_time: 0.0055  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:25:01 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: reid_r50_8xb32-6e_mot17train80_test-mot17val20_20220906_091626\n",
            "09/06 09:25:01 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "09/06 09:25:19 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][50/1576]  lr: 1.0000e-02  eta: 0:08:03  time: 0.3158  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:25:35 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][100/1576]  lr: 1.0000e-02  eta: 0:07:47  time: 0.3160  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:25:51 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][150/1576]  lr: 1.0000e-02  eta: 0:07:31  time: 0.3164  data_time: 0.0062  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:26:07 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][200/1576]  lr: 1.0000e-02  eta: 0:07:15  time: 0.3159  data_time: 0.0062  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:26:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][250/1576]  lr: 1.0000e-02  eta: 0:07:00  time: 0.3163  data_time: 0.0065  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:26:38 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][300/1576]  lr: 1.0000e-02  eta: 0:06:44  time: 0.3149  data_time: 0.0056  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:26:54 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][350/1576]  lr: 1.0000e-02  eta: 0:06:28  time: 0.3167  data_time: 0.0063  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:27:10 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][400/1576]  lr: 1.0000e-02  eta: 0:06:12  time: 0.3148  data_time: 0.0057  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:27:18 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: reid_r50_8xb32-6e_mot17train80_test-mot17val20_20220906_091626\n",
            "09/06 09:27:26 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][450/1576]  lr: 1.0000e-02  eta: 0:05:56  time: 0.3127  data_time: 0.0057  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:27:42 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][500/1576]  lr: 1.0000e-02  eta: 0:05:40  time: 0.3186  data_time: 0.0064  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:27:58 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][550/1576]  lr: 1.0000e-02  eta: 0:05:24  time: 0.3151  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:28:13 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][600/1576]  lr: 1.0000e-02  eta: 0:05:09  time: 0.3158  data_time: 0.0058  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:28:29 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][650/1576]  lr: 1.0000e-02  eta: 0:04:53  time: 0.3162  data_time: 0.0063  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:28:45 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][700/1576]  lr: 1.0000e-02  eta: 0:04:37  time: 0.3156  data_time: 0.0066  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:29:01 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][750/1576]  lr: 1.0000e-02  eta: 0:04:21  time: 0.3164  data_time: 0.0060  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:29:17 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][800/1576]  lr: 1.0000e-02  eta: 0:04:05  time: 0.3172  data_time: 0.0067  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:29:33 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][850/1576]  lr: 1.0000e-02  eta: 0:03:49  time: 0.3134  data_time: 0.0054  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:29:48 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][900/1576]  lr: 1.0000e-02  eta: 0:03:34  time: 0.3172  data_time: 0.0066  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:30:04 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][950/1576]  lr: 1.0000e-02  eta: 0:03:18  time: 0.3129  data_time: 0.0059  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:30:20 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1000/1576]  lr: 1.0000e-02  eta: 0:03:02  time: 0.3145  data_time: 0.0059  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:30:36 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1050/1576]  lr: 1.0000e-02  eta: 0:02:46  time: 0.3142  data_time: 0.0066  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:30:52 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1100/1576]  lr: 1.0000e-02  eta: 0:02:30  time: 0.3169  data_time: 0.0063  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:31:08 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1150/1576]  lr: 1.0000e-02  eta: 0:02:14  time: 0.3158  data_time: 0.0064  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:31:23 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1200/1576]  lr: 1.0000e-02  eta: 0:01:59  time: 0.3150  data_time: 0.0067  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:31:39 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1250/1576]  lr: 1.0000e-02  eta: 0:01:43  time: 0.3169  data_time: 0.0056  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:31:55 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1300/1576]  lr: 1.0000e-02  eta: 0:01:27  time: 0.3153  data_time: 0.0061  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:32:11 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1350/1576]  lr: 1.0000e-02  eta: 0:01:11  time: 0.3148  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:32:27 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1400/1576]  lr: 1.0000e-02  eta: 0:00:55  time: 0.3171  data_time: 0.0057  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:32:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: reid_r50_8xb32-6e_mot17train80_test-mot17val20_20220906_091626\n",
            "09/06 09:32:42 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1450/1576]  lr: 1.0000e-02  eta: 0:00:39  time: 0.3148  data_time: 0.0051  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:32:58 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1500/1576]  lr: 1.0000e-02  eta: 0:00:24  time: 0.3157  data_time: 0.0053  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:33:14 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(train) [2][1550/1576]  lr: 1.0000e-02  eta: 0:00:08  time: 0.3156  data_time: 0.0068  memory: 3519  triplet_loss: 0.0000  ce_loss: 0.0002  accuracy_top-1: 100.0000  loss: 0.0002\n",
            "09/06 09:33:22 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Exp name: reid_r50_8xb32-6e_mot17train80_test-mot17val20_20220906_091626\n",
            "09/06 09:33:22 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BaseReID(\n",
              "  (data_preprocessor): ClsDataPreprocessor()\n",
              "  (backbone): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (layer2): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (layer3): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "    (layer4): ResLayer(\n",
              "      (0): Bottleneck(\n",
              "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (drop_path): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  init_cfg=[{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]\n",
              "  (neck): GlobalAveragePooling(\n",
              "    (gap): AvgPool2d(kernel_size=(8, 4), stride=1, padding=0)\n",
              "  )\n",
              "  (head): LinearReIDHead(\n",
              "    (loss_cls): CrossEntropyLoss()\n",
              "    (loss_triplet): TripletLoss(\n",
              "      (ranking_loss): MarginRankingLoss()\n",
              "    )\n",
              "    (fcs): ModuleList(\n",
              "      (0): FcModule(\n",
              "        (fc): Linear(in_features=2048, out_features=1024, bias=True)\n",
              "        (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activate): ReLU(inplace=True)\n",
              "      )\n",
              "      init_cfg={'type': 'Kaiming', 'layer': 'Linear'}\n",
              "    )\n",
              "    (fc_out): Linear(in_features=1024, out_features=128, bias=True)\n",
              "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (classifier): Linear(in_features=128, out_features=380, bias=True)\n",
              "  )\n",
              "  init_cfg={'type': 'Normal', 'layer': 'Linear', 'mean': 0, 'std': 0.01, 'bias': 0}\n",
              ")\n",
              "init_cfg={'type': 'Pretrained', 'checkpoint': 'https://download.openmmlab.com/mmclassification/v0/resnet/resnet50_batch256_imagenet_20200708-cfb998bf.pth'}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os.path as osp\n",
        "\n",
        "from mmengine.utils import mkdir_or_exist\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "runner = Runner.from_cfg(cfg)\n",
        "runner.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
      "metadata": {
        "id": "e5ac4b40-7023-498a-9ddf-bc06ff2100af",
        "tags": []
      },
      "source": [
        "### **Test the DeepSORT model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "c837c657-cc81-426d-8060-ad19f5494461",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c837c657-cc81-426d-8060-ad19f5494461",
        "outputId": "9950328d-6ef9-4add-f79d-ceb576eef936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Config:\n",
            "model = dict(\n",
            "    data_preprocessor=dict(\n",
            "        type='TrackDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        bgr_to_rgb=True,\n",
            "        rgb_to_bgr=False,\n",
            "        pad_size_divisor=32),\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        _scope_='mmdet',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            style='pytorch',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "                clip_border=False),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(\n",
            "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
            "                loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=1,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                    clip_border=False),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100)),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
            "    type='DeepSORT',\n",
            "    motion=dict(type='KalmanFilter', center_only=False),\n",
            "    reid=dict(\n",
            "        type='BaseReID',\n",
            "        data_preprocessor=None,\n",
            "        backbone=dict(\n",
            "            type='mmcls.ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(3, ),\n",
            "            style='pytorch'),\n",
            "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "        head=dict(\n",
            "            type='LinearReIDHead',\n",
            "            num_fcs=1,\n",
            "            in_channels=2048,\n",
            "            fc_channels=1024,\n",
            "            out_channels=128,\n",
            "            num_classes=380,\n",
            "            loss_cls=dict(type='mmcls.CrossEntropyLoss', loss_weight=1.0),\n",
            "            loss_triplet=dict(type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "            norm_cfg=dict(type='BN1d'),\n",
            "            act_cfg=dict(type='ReLU')),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
            "    tracker=dict(\n",
            "        type='SORTTracker',\n",
            "        obj_score_thr=0.5,\n",
            "        reid=dict(\n",
            "            num_samples=10,\n",
            "            img_scale=(256, 128),\n",
            "            img_norm_cfg=None,\n",
            "            match_score_thr=2.0),\n",
            "        match_iou_thr=0.5,\n",
            "        momentums=None,\n",
            "        num_tentatives=2,\n",
            "        num_frames_retain=100))\n",
            "dataset_type = 'MOTChallengeDataset'\n",
            "data_root = 'data/MOT17/'\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=True,\n",
            "        transforms=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "            dict(\n",
            "                type='mmdet.RandomResize',\n",
            "                scale=(1088, 1088),\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                clip_object_border=False),\n",
            "            dict(type='mmdet.PhotoMetricDistortion')\n",
            "        ]),\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=False,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='mmdet.RandomCrop',\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False)\n",
            "        ]),\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=True,\n",
            "        transforms=[dict(type='mmdet.RandomFlip', prob=0.5)]),\n",
            "    dict(type='PackTrackInputs', ref_prefix='ref', num_key_frames=1)\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "    dict(type='mmdet.Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "    dict(type='PackTrackInputs', pack_single_img=True)\n",
            "]\n",
            "train_dataloader = None\n",
            "val_dataloader = None\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='VideoSampler'),\n",
            "    dataset=dict(\n",
            "        type='MOTChallengeDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        ann_file='annotations/half-val_cocoformat.json',\n",
            "        data_prefix=dict(img_path='train'),\n",
            "        ref_img_sampler=None,\n",
            "        load_as_video=True,\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "            dict(type='mmdet.Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "            dict(type='PackTrackInputs', pack_single_img=True)\n",
            "        ]))\n",
            "val_evaluator = None\n",
            "test_evaluator = dict(\n",
            "    type='MOTChallengeMetrics', metric=['HOTA', 'CLEAR', 'Identity'])\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='TrackVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='TrackLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='deepsort_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "train_cfg = None\n",
            "val_cfg = None\n",
            "test_cfg = dict(type='TestLoop')\n",
            "work_dir = './tutorial_exps'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import mmengine\n",
        "\n",
        "cfg = mmengine.Config.fromfile('./configs/mot/deepsort/deepsort_faster-rcnn_r50_fpn_8xb2-4e_mot17halftrain_test-mot17halfval.py')\n",
        "cfg.test_dataloader.dataset.data_root = 'data/MOT17_tiny/'\n",
        "cfg.test_dataloader.dataset.test_mode = True\n",
        "cfg.train_dataloader = cfg.train_cfg = None\n",
        "cfg.val_dataloader = cfg.val_cfg = cfg.val_evaluator = None\n",
        "cfg.visualizer.name = 'deepsort_visualizer'\n",
        "cfg.model.detector.init_cfg.checkpoint = './tutorial_exps/detector/epoch_4.pth'\n",
        "cfg.model.reid.init_cfg.checkpoint = './tutorial_exps/reid/epoch_2.pth'\n",
        "\n",
        "cfg.work_dir = './tutorial_exps'\n",
        "cfg.randomness = dict(seed=0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "print(f'Config:\\n{cfg.pretty_text}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "29c9f531-3ea9-42d3-9fb3-bcdd13594406",
        "outputId": "6d133c91-8323-45c0-e031-5bc8be89485d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "09/06 09:37:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 0\n",
            "    GPU 0: Tesla T4\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.1, V11.1.105\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "    PyTorch: 1.10.0+cu111\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "    TorchVision: 0.11.0+cu111\n",
            "    OpenCV: 4.6.0\n",
            "    MMEngine: 0.1.0\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 0\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "09/06 09:37:05 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Config:\n",
            "model = dict(\n",
            "    data_preprocessor=dict(\n",
            "        type='TrackDataPreprocessor',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        bgr_to_rgb=True,\n",
            "        rgb_to_bgr=False,\n",
            "        pad_size_divisor=32),\n",
            "    detector=dict(\n",
            "        type='FasterRCNN',\n",
            "        _scope_='mmdet',\n",
            "        backbone=dict(\n",
            "            type='ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(0, 1, 2, 3),\n",
            "            frozen_stages=1,\n",
            "            norm_cfg=dict(type='BN', requires_grad=True),\n",
            "            norm_eval=True,\n",
            "            style='pytorch',\n",
            "            init_cfg=dict(\n",
            "                type='Pretrained', checkpoint='torchvision://resnet50')),\n",
            "        neck=dict(\n",
            "            type='FPN',\n",
            "            in_channels=[256, 512, 1024, 2048],\n",
            "            out_channels=256,\n",
            "            num_outs=5),\n",
            "        rpn_head=dict(\n",
            "            type='RPNHead',\n",
            "            in_channels=256,\n",
            "            feat_channels=256,\n",
            "            anchor_generator=dict(\n",
            "                type='AnchorGenerator',\n",
            "                scales=[8],\n",
            "                ratios=[0.5, 1.0, 2.0],\n",
            "                strides=[4, 8, 16, 32, 64]),\n",
            "            bbox_coder=dict(\n",
            "                type='DeltaXYWHBBoxCoder',\n",
            "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                target_stds=[1.0, 1.0, 1.0, 1.0],\n",
            "                clip_border=False),\n",
            "            loss_cls=dict(\n",
            "                type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
            "            loss_bbox=dict(\n",
            "                type='SmoothL1Loss', beta=0.1111111111111111,\n",
            "                loss_weight=1.0)),\n",
            "        roi_head=dict(\n",
            "            type='StandardRoIHead',\n",
            "            bbox_roi_extractor=dict(\n",
            "                type='SingleRoIExtractor',\n",
            "                roi_layer=dict(\n",
            "                    type='RoIAlign', output_size=7, sampling_ratio=0),\n",
            "                out_channels=256,\n",
            "                featmap_strides=[4, 8, 16, 32]),\n",
            "            bbox_head=dict(\n",
            "                type='Shared2FCBBoxHead',\n",
            "                in_channels=256,\n",
            "                fc_out_channels=1024,\n",
            "                roi_feat_size=7,\n",
            "                num_classes=1,\n",
            "                bbox_coder=dict(\n",
            "                    type='DeltaXYWHBBoxCoder',\n",
            "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
            "                    target_stds=[0.1, 0.1, 0.2, 0.2],\n",
            "                    clip_border=False),\n",
            "                reg_class_agnostic=False,\n",
            "                loss_cls=dict(\n",
            "                    type='CrossEntropyLoss',\n",
            "                    use_sigmoid=False,\n",
            "                    loss_weight=1.0),\n",
            "                loss_bbox=dict(type='SmoothL1Loss', loss_weight=1.0))),\n",
            "        train_cfg=dict(\n",
            "            rpn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.7,\n",
            "                    neg_iou_thr=0.3,\n",
            "                    min_pos_iou=0.3,\n",
            "                    match_low_quality=True,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=256,\n",
            "                    pos_fraction=0.5,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=False),\n",
            "                allowed_border=-1,\n",
            "                pos_weight=-1,\n",
            "                debug=False),\n",
            "            rpn_proposal=dict(\n",
            "                nms_pre=2000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                assigner=dict(\n",
            "                    type='MaxIoUAssigner',\n",
            "                    pos_iou_thr=0.5,\n",
            "                    neg_iou_thr=0.5,\n",
            "                    min_pos_iou=0.5,\n",
            "                    match_low_quality=False,\n",
            "                    ignore_iof_thr=-1),\n",
            "                sampler=dict(\n",
            "                    type='RandomSampler',\n",
            "                    num=512,\n",
            "                    pos_fraction=0.25,\n",
            "                    neg_pos_ub=-1,\n",
            "                    add_gt_as_proposals=True),\n",
            "                pos_weight=-1,\n",
            "                debug=False)),\n",
            "        test_cfg=dict(\n",
            "            rpn=dict(\n",
            "                nms_pre=1000,\n",
            "                max_per_img=1000,\n",
            "                nms=dict(type='nms', iou_threshold=0.7),\n",
            "                min_bbox_size=0),\n",
            "            rcnn=dict(\n",
            "                score_thr=0.05,\n",
            "                nms=dict(type='nms', iou_threshold=0.5),\n",
            "                max_per_img=100)),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint='./tutorial_exps/detector/epoch_4.pth')),\n",
            "    type='DeepSORT',\n",
            "    motion=dict(type='KalmanFilter', center_only=False),\n",
            "    reid=dict(\n",
            "        type='BaseReID',\n",
            "        data_preprocessor=None,\n",
            "        backbone=dict(\n",
            "            type='mmcls.ResNet',\n",
            "            depth=50,\n",
            "            num_stages=4,\n",
            "            out_indices=(3, ),\n",
            "            style='pytorch'),\n",
            "        neck=dict(type='GlobalAveragePooling', kernel_size=(8, 4), stride=1),\n",
            "        head=dict(\n",
            "            type='LinearReIDHead',\n",
            "            num_fcs=1,\n",
            "            in_channels=2048,\n",
            "            fc_channels=1024,\n",
            "            out_channels=128,\n",
            "            num_classes=380,\n",
            "            loss_cls=dict(type='mmcls.CrossEntropyLoss', loss_weight=1.0),\n",
            "            loss_triplet=dict(type='TripletLoss', margin=0.3, loss_weight=1.0),\n",
            "            norm_cfg=dict(type='BN1d'),\n",
            "            act_cfg=dict(type='ReLU')),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained', checkpoint='./tutorial_exps/reid/epoch_2.pth')),\n",
            "    tracker=dict(\n",
            "        type='SORTTracker',\n",
            "        obj_score_thr=0.5,\n",
            "        reid=dict(\n",
            "            num_samples=10,\n",
            "            img_scale=(256, 128),\n",
            "            img_norm_cfg=None,\n",
            "            match_score_thr=2.0),\n",
            "        match_iou_thr=0.5,\n",
            "        momentums=None,\n",
            "        num_tentatives=2,\n",
            "        num_frames_retain=100))\n",
            "dataset_type = 'MOTChallengeDataset'\n",
            "data_root = 'data/MOT17/'\n",
            "train_pipeline = [\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=True,\n",
            "        transforms=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "            dict(\n",
            "                type='mmdet.RandomResize',\n",
            "                scale=(1088, 1088),\n",
            "                ratio_range=(0.8, 1.2),\n",
            "                keep_ratio=True,\n",
            "                clip_object_border=False),\n",
            "            dict(type='mmdet.PhotoMetricDistortion')\n",
            "        ]),\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=False,\n",
            "        transforms=[\n",
            "            dict(\n",
            "                type='mmdet.RandomCrop',\n",
            "                crop_size=(1088, 1088),\n",
            "                bbox_clip_border=False)\n",
            "        ]),\n",
            "    dict(\n",
            "        type='TransformBroadcaster',\n",
            "        share_random_params=True,\n",
            "        transforms=[dict(type='mmdet.RandomFlip', prob=0.5)]),\n",
            "    dict(type='PackTrackInputs', ref_prefix='ref', num_key_frames=1)\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "    dict(type='mmdet.Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "    dict(type='PackTrackInputs', pack_single_img=True)\n",
            "]\n",
            "train_dataloader = None\n",
            "val_dataloader = None\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    drop_last=False,\n",
            "    sampler=dict(type='VideoSampler'),\n",
            "    dataset=dict(\n",
            "        type='MOTChallengeDataset',\n",
            "        data_root='data/MOT17_tiny/',\n",
            "        ann_file='annotations/half-val_cocoformat.json',\n",
            "        data_prefix=dict(img_path='train'),\n",
            "        ref_img_sampler=None,\n",
            "        load_as_video=True,\n",
            "        test_mode=True,\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadTrackAnnotations', with_instance_id=True),\n",
            "            dict(type='mmdet.Resize', scale=(1088, 1088), keep_ratio=True),\n",
            "            dict(type='PackTrackInputs', pack_single_img=True)\n",
            "        ]))\n",
            "val_evaluator = None\n",
            "test_evaluator = dict(\n",
            "    type='MOTChallengeMetrics', metric=['HOTA', 'CLEAR', 'Identity'])\n",
            "default_scope = 'mmtrack'\n",
            "default_hooks = dict(\n",
            "    timer=dict(type='IterTimerHook'),\n",
            "    logger=dict(type='LoggerHook', interval=50),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    checkpoint=dict(type='CheckpointHook', interval=1),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    visualization=dict(type='TrackVisualizationHook', draw=False))\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n",
            "    dist_cfg=dict(backend='nccl'))\n",
            "vis_backends = [dict(type='LocalVisBackend')]\n",
            "visualizer = dict(\n",
            "    type='TrackLocalVisualizer',\n",
            "    vis_backends=[dict(type='LocalVisBackend')],\n",
            "    name='deepsort_visualizer')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume = False\n",
            "train_cfg = None\n",
            "val_cfg = None\n",
            "test_cfg = dict(type='TestLoop')\n",
            "work_dir = './tutorial_exps'\n",
            "randomness = dict(seed=0, deterministic=False)\n",
            "gpu_ids = range(0, 1)\n",
            "\n",
            "Result has been saved to /content/mmtracking/tutorial_exps/modules_statistic_results.json\n",
            "09/06 09:37:06 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "09/06 09:37:06 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: ./tutorial_exps/detector/epoch_4.pth\n",
            "09/06 09:37:06 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - local loads checkpoint from path: ./tutorial_exps/detector/epoch_4.pth\n",
            "09/06 09:37:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "09/06 09:37:06 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - load model from: ./tutorial_exps/reid/epoch_2.pth\n",
            "09/06 09:37:06 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - local loads checkpoint from path: ./tutorial_exps/reid/epoch_2.pth\n",
            "09/06 09:37:06 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: data_preprocessor.mean, data_preprocessor.std\n",
            "\n",
            "loading annotations into memory...\n",
            "Done (t=10.59s)\n",
            "creating index...\n",
            "index created!\n",
            "09/06 09:37:28 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [50/823]    eta: 0:02:33  time: 0.1980  data_time: 0.0045  memory: 3519  \n",
            "09/06 09:37:38 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [100/823]    eta: 0:02:15  time: 0.1873  data_time: 0.0042  memory: 2148  \n",
            "09/06 09:37:49 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [150/823]    eta: 0:02:50  time: 0.2529  data_time: 0.0073  memory: 2148  \n",
            "09/06 09:38:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [200/823]    eta: 0:02:47  time: 0.2690  data_time: 0.0107  memory: 2190  \n",
            "09/06 09:38:16 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [250/823]    eta: 0:02:24  time: 0.2518  data_time: 0.0070  memory: 2190  \n",
            "09/06 09:38:28 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [300/823]    eta: 0:02:05  time: 0.2391  data_time: 0.0063  memory: 2236  \n",
            "09/06 09:38:40 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [350/823]    eta: 0:01:42  time: 0.2171  data_time: 0.0048  memory: 2237  \n",
            "09/06 09:38:51 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [400/823]    eta: 0:01:35  time: 0.2247  data_time: 0.0056  memory: 2224  \n",
            "09/06 09:39:03 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [450/823]    eta: 0:01:27  time: 0.2335  data_time: 0.0058  memory: 2218  \n",
            "09/06 09:39:14 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [500/823]    eta: 0:01:10  time: 0.2188  data_time: 0.0106  memory: 2212  \n",
            "09/06 09:39:25 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [550/823]    eta: 0:01:01  time: 0.2267  data_time: 0.0098  memory: 2206  \n",
            "09/06 09:39:36 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [600/823]    eta: 0:00:49  time: 0.2198  data_time: 0.0072  memory: 2200  \n",
            "09/06 09:39:48 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [650/823]    eta: 0:00:41  time: 0.2403  data_time: 0.0043  memory: 2264  \n",
            "09/06 09:40:00 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [700/823]    eta: 0:00:29  time: 0.2418  data_time: 0.0047  memory: 2372  \n",
            "09/06 09:40:12 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [750/823]    eta: 0:00:17  time: 0.2427  data_time: 0.0041  memory: 2246  \n",
            "09/06 09:40:26 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [800/823]    eta: 0:00:05  time: 0.2434  data_time: 0.0041  memory: 2317  \n",
            "\n",
            "Eval Config:\n",
            "USE_PARALLEL         : False                         \n",
            "NUM_PARALLEL_CORES   : 8                             \n",
            "BREAK_ON_ERROR       : True                          \n",
            "RETURN_ON_ERROR      : False                         \n",
            "LOG_ON_ERROR         : /usr/local/lib/python3.7/dist-packages/error_log.txt\n",
            "PRINT_RESULTS        : True                          \n",
            "PRINT_ONLY_COMBINED  : False                         \n",
            "PRINT_CONFIG         : True                          \n",
            "TIME_PROGRESS        : True                          \n",
            "DISPLAY_LESS_PROGRESS : True                          \n",
            "OUTPUT_SUMMARY       : True                          \n",
            "OUTPUT_EMPTY_CLASSES : True                          \n",
            "OUTPUT_DETAILED      : True                          \n",
            "PLOT_CURVES          : True                          \n",
            "\n",
            "MotChallenge2DBox Config:\n",
            "GT_FOLDER            : /tmp/tmpw97bk3y0/gt           \n",
            "TRACKERS_FOLDER      : /tmp/tmpw97bk3y0              \n",
            "OUTPUT_FOLDER        : None                          \n",
            "TRACKERS_TO_EVAL     : ['default-tracker']           \n",
            "CLASSES_TO_EVAL      : ['pedestrian']                \n",
            "BENCHMARK            : MOT17                         \n",
            "SPLIT_TO_EVAL        : train                         \n",
            "INPUT_AS_ZIP         : False                         \n",
            "PRINT_CONFIG         : True                          \n",
            "DO_PREPROC           : True                          \n",
            "TRACKER_SUB_FOLDER   :                               \n",
            "OUTPUT_SUB_FOLDER    :                               \n",
            "TRACKER_DISPLAY_NAMES : None                          \n",
            "SEQMAP_FOLDER        : None                          \n",
            "SEQMAP_FILE          : /tmp/tmpw97bk3y0/default-tracker/videoseq.txt\n",
            "SEQ_INFO             : {'MOT17-02-FRCNN': 299, 'MOT17-04-FRCNN': 524}\n",
            "GT_LOC_FORMAT        : {gt_folder}/{seq}.txt         \n",
            "SKIP_SPLIT_FOL       : True                          \n",
            "\n",
            "CLEAR Config:\n",
            "METRICS              : ['CLEAR']                     \n",
            "THRESHOLD            : 0.5                           \n",
            "PRINT_CONFIG         : True                          \n",
            "\n",
            "Identity Config:\n",
            "METRICS              : ['Identity']                  \n",
            "THRESHOLD            : 0.5                           \n",
            "PRINT_CONFIG         : True                          \n",
            "\n",
            "Evaluating 1 tracker(s) on 2 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, CLEAR, Identity, Count\n",
            "\n",
            "\n",
            "Evaluating default-tracker\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/trackeval/datasets/mot_challenge_2d_box.py:228: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  time_data = np.asarray(read_data[time_key], dtype=np.float)\n",
            "/usr/local/lib/python3.7/dist-packages/trackeval/datasets/mot_challenge_2d_box.py:359: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  to_remove_tracker = np.array([], np.int)\n",
            "/usr/local/lib/python3.7/dist-packages/trackeval/metrics/hota.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  res[field] = np.zeros((len(self.array_labels)), dtype=np.float)\n",
            "/usr/local/lib/python3.7/dist-packages/trackeval/metrics/identity.py:83: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  res['IDFN'] = fn_mat[match_rows, match_cols].sum().astype(np.int)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 eval_sequence(MOT17-02-FRCNN, default-tracker)                         0.4670 sec\n",
            "2 eval_sequence(MOT17-04-FRCNN, default-tracker)                         1.3160 sec\n",
            "\n",
            "All sequences for default-tracker finished in 1.78 seconds\n",
            "\n",
            "HOTA: default-tracker-pedestrian   HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      RHOTA     HOTA(0)   LocA(0)   HOTALocA(0)\n",
            "MOT17-02-FRCNN                     26.07     39.469    17.888    46.443    63.395    20.298    59.499    79.439    28.497    34.31     68.423    23.476    \n",
            "MOT17-04-FRCNN                     54.514    66.438    45.771    70.914    82.049    51.423    62.818    84.856    56.637    64.719    81.721    52.889    \n",
            "COMBINED                           47.481    57.937    40.091    63.815    77.25     45.144    62.333    83.649    50.152    57.312    78.488    44.983    \n",
            "\n",
            "CLEAR: default-tracker-pedestrian  MOTA      MOTP      MODA      CLR_Re    CLR_Pr    MTR       PTR       MLR       sMOTA     CLR_TP    CLR_FN    CLR_FP    IDSW      MT        PT        ML        Frag      \n",
            "MOT17-02-FRCNN                     28.279    77.975    37.287    55.273    75.449    20.755    60.377    18.868    16.105    5461      4419      1777      890       11        32        10        346       \n",
            "MOT17-04-FRCNN                     77.19     82.679    80.937    83.684    96.823    65.217    31.884    2.8986    62.695    20233     3945      664       906       45        22        2         285       \n",
            "COMBINED                           63.001    81.679    68.275    75.442    91.324    45.902    44.262    9.8361    49.18     25694     8364      2441      1796      56        54        12        631       \n",
            "\n",
            "Identity: default-tracker-pedestrianIDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
            "MOT17-02-FRCNN                     29.186    25.283    34.512    2498      7382      4740      \n",
            "MOT17-04-FRCNN                     59.448    55.414    64.114    13398     10780     7499      \n",
            "COMBINED                           51.118    46.673    56.499    15896     18162     12239     \n",
            "\n",
            "Count: default-tracker-pedestrian  Dets      GT_Dets   IDs       GT_IDs    \n",
            "MOT17-02-FRCNN                     7238      9880      434       53        \n",
            "MOT17-04-FRCNN                     20897     24178     188       69        \n",
            "COMBINED                           28135     34058     622       122       \n",
            "09/06 09:40:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating HOTA Metrics...\n",
            "09/06 09:40:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating CLEAR Metrics...\n",
            "09/06 09:40:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Evaluating Identity Metrics...\n",
            "09/06 09:40:34 - mmengine - \u001b[4m\u001b[37mINFO\u001b[0m - Epoch(test) [823/823]  motchallenge-metric/HOTA: 0.4748  motchallenge-metric/AssA: 0.4009  motchallenge-metric/DetA: 0.5794  motchallenge-metric/MOTA: 0.6300  motchallenge-metric/MOTP: 0.8168  motchallenge-metric/IDSW: 1796.0000  motchallenge-metric/TP: 25694.0000  motchallenge-metric/FP: 2441.0000  motchallenge-metric/FN: 8364.0000  motchallenge-metric/Frag: 631.0000  motchallenge-metric/MT: 56.0000  motchallenge-metric/ML: 12.0000  motchallenge-metric/IDF1: 0.5112  motchallenge-metric/IDTP: 15896.0000  motchallenge-metric/IDFN: 18162.0000  motchallenge-metric/IDFP: 12239.0000  motchallenge-metric/IDP: 0.5650  motchallenge-metric/IDR: 0.4667\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'motchallenge-metric/HOTA': 0.47480527965525604,\n",
              " 'motchallenge-metric/AssA': 0.40090624838232497,\n",
              " 'motchallenge-metric/DetA': 0.5793687250260392,\n",
              " 'motchallenge-metric/MOTA': 0.6300135063714839,\n",
              " 'motchallenge-metric/MOTP': 0.8167920002689131,\n",
              " 'motchallenge-metric/IDSW': 1796.0,\n",
              " 'motchallenge-metric/TP': 25694.0,\n",
              " 'motchallenge-metric/FP': 2441.0,\n",
              " 'motchallenge-metric/FN': 8364.0,\n",
              " 'motchallenge-metric/Frag': 631.0,\n",
              " 'motchallenge-metric/MT': 56.0,\n",
              " 'motchallenge-metric/ML': 12.0,\n",
              " 'motchallenge-metric/IDF1': 0.5111829305548856,\n",
              " 'motchallenge-metric/IDTP': 15896.0,\n",
              " 'motchallenge-metric/IDFN': 18162.0,\n",
              " 'motchallenge-metric/IDFP': 12239.0,\n",
              " 'motchallenge-metric/IDP': 0.5649902256975298,\n",
              " 'motchallenge-metric/IDR': 0.46673321980151505}"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from mmengine.model import is_model_wrapper\n",
        "from mmengine.runner import Runner\n",
        "\n",
        "runner = Runner.from_cfg(cfg)\n",
        "\n",
        "if is_model_wrapper(runner.model):\n",
        "    runner.model.module.init_weights()\n",
        "else:\n",
        "    runner.model.init_weights()\n",
        "\n",
        "runner.test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b4dd8ace9b5467e9e7c0214df6df1a9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a722030c2344bf6a5ba1941c9e056de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a6f0f21a864752bb77a435e5633c5f",
            "placeholder": "​",
            "style": "IPY_MODEL_f4510cc71cf54df785fbe760b7dfc32c",
            "value": " 160M/160M [00:17&lt;00:00, 9.42MB/s]"
          }
        },
        "20b5b5e82f5548c98037ee236732ccfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "28ef474b2c7c466baa81c1196f8e7505": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_504570ec6de24f40b824fb8eacc65447",
            "max": 102491894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9470c130a69411b8be481f4aa045d26",
            "value": 102491894
          }
        },
        "2db8224b7bb849c0a3c8a281bb57eb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b811cd2dd72040fe86cdc5238b522d06",
              "IPY_MODEL_378b791183a24c558b2ce4afc1fe8a57",
              "IPY_MODEL_9f46a04413cf4cce9f56a710aebe1424"
            ],
            "layout": "IPY_MODEL_fb5e2db40e004e21a852c9f28740615c"
          }
        },
        "33267c31afd64c58b153a357aaa4569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_936d523d65254c10a9c64033283ca0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea9a77bcea840e686d3525d4ef86cc8",
            "value": " 170M/170M [00:18&lt;00:00, 10.1MB/s]"
          }
        },
        "34594c7fd26c4f61af5e4ec5b34b6b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8727613cf45f4cd4a79557afd1973632",
              "IPY_MODEL_28ef474b2c7c466baa81c1196f8e7505",
              "IPY_MODEL_7b268f5a3b334d2c89ae8d43fda6eb53"
            ],
            "layout": "IPY_MODEL_9d467daaa30e44288dd49152948db460"
          }
        },
        "34b3be1af1704bd4a1a25992ff3a2c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c5e87a7ba0f4b8395a3fd0027508930",
            "max": 167290877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a83c0a2e5ee8432d9ecb05468194f3ed",
            "value": 167290877
          }
        },
        "357be7f73b2848f89efe394758edc839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36f603cf7dab445ab6120b805799c1d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "378b791183a24c558b2ce4afc1fe8a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3942fdab3efa47e98ef1398b27eade57",
            "max": 182353916,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_357be7f73b2848f89efe394758edc839",
            "value": 182353916
          }
        },
        "3942fdab3efa47e98ef1398b27eade57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a09540c2a4247debd7c35b384e7ebed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d25971bbb3444b797b0faac0a934ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40b5616f3b3741d68210206a1d852418": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4679ff15b0db45fb9931757e0328d296": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d7f321bb1fe4f32b3c1733a846ef8f5",
            "placeholder": "​",
            "style": "IPY_MODEL_dc309139c6764cefa17ef542ebb36d3e",
            "value": "100%"
          }
        },
        "4757d999925e44748b3b4b8476ff7069": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64133dab9fa94eb9ad7819da4740a90f",
              "IPY_MODEL_34b3be1af1704bd4a1a25992ff3a2c33",
              "IPY_MODEL_1a722030c2344bf6a5ba1941c9e056de"
            ],
            "layout": "IPY_MODEL_e0b78a16c9d8488eb6f2b78788bc1987"
          }
        },
        "482683c5f93f41108ef0added3850519": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea9a77bcea840e686d3525d4ef86cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eb851325f4b4cab82b8cbd979237520": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec62bc9001d349e696b8d82942e5b8c4",
            "placeholder": "​",
            "style": "IPY_MODEL_b55031500bb345b58d0676c47e3c7843",
            "value": "100%"
          }
        },
        "4ebcc9b78ac64aedb146685a2437612c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "504570ec6de24f40b824fb8eacc65447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7f321bb1fe4f32b3c1733a846ef8f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64133dab9fa94eb9ad7819da4740a90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36f603cf7dab445ab6120b805799c1d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f572376e2dbb437c95e1f62820d6f0d3",
            "value": "100%"
          }
        },
        "64e629d4b1c74d2ab6c9ddc52ff4a2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a09540c2a4247debd7c35b384e7ebed",
            "max": 102530333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20b5b5e82f5548c98037ee236732ccfe",
            "value": 102530333
          }
        },
        "7b268f5a3b334d2c89ae8d43fda6eb53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4dd8ace9b5467e9e7c0214df6df1a9",
            "placeholder": "​",
            "style": "IPY_MODEL_e495e81fecf844a4ae4a15ca9cb0329c",
            "value": " 97.7M/97.7M [00:10&lt;00:00, 10.1MB/s]"
          }
        },
        "8727613cf45f4cd4a79557afd1973632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9793eaee82db45beaddf9e80cab6d0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_e75e2e078b4246a9984fa0841de27a15",
            "value": "100%"
          }
        },
        "936d523d65254c10a9c64033283ca0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9793eaee82db45beaddf9e80cab6d0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f236bb20444b919f136766394978ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c5adcbe51ef438db298bff6a09c2065": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c5e87a7ba0f4b8395a3fd0027508930": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d467daaa30e44288dd49152948db460": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2fb13e136642728fbc97c8d7390118": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2d50cb741b4a79a13f0bf4a2b2242b",
            "max": 177862517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c5adcbe51ef438db298bff6a09c2065",
            "value": 177862517
          }
        },
        "9f46a04413cf4cce9f56a710aebe1424": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b704c75bb577455dbac176c728b5540b",
            "placeholder": "​",
            "style": "IPY_MODEL_e34931d882f44879aee48bfd46d62dce",
            "value": " 174M/174M [00:20&lt;00:00, 9.14MB/s]"
          }
        },
        "a3fc7d320ed3417d833db4e9db0fce5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb851325f4b4cab82b8cbd979237520",
              "IPY_MODEL_9f2fb13e136642728fbc97c8d7390118",
              "IPY_MODEL_33267c31afd64c58b153a357aaa4569b"
            ],
            "layout": "IPY_MODEL_98f236bb20444b919f136766394978ff"
          }
        },
        "a5c4355973c342acbae02ff5c32a677f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a83c0a2e5ee8432d9ecb05468194f3ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b55031500bb345b58d0676c47e3c7843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b704c75bb577455dbac176c728b5540b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b811cd2dd72040fe86cdc5238b522d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40b5616f3b3741d68210206a1d852418",
            "placeholder": "​",
            "style": "IPY_MODEL_482683c5f93f41108ef0added3850519",
            "value": "100%"
          }
        },
        "b9470c130a69411b8be481f4aa045d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1a6f0f21a864752bb77a435e5633c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8911837396446c19d76bc22c5be63e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4679ff15b0db45fb9931757e0328d296",
              "IPY_MODEL_64e629d4b1c74d2ab6c9ddc52ff4a2a9",
              "IPY_MODEL_e00476c38c4d473191eeed5d6c42ecce"
            ],
            "layout": "IPY_MODEL_a5c4355973c342acbae02ff5c32a677f"
          }
        },
        "dc309139c6764cefa17ef542ebb36d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd2d50cb741b4a79a13f0bf4a2b2242b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e00476c38c4d473191eeed5d6c42ecce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ebcc9b78ac64aedb146685a2437612c",
            "placeholder": "​",
            "style": "IPY_MODEL_3d25971bbb3444b797b0faac0a934ffb",
            "value": " 97.8M/97.8M [00:00&lt;00:00, 165MB/s]"
          }
        },
        "e0b78a16c9d8488eb6f2b78788bc1987": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e34931d882f44879aee48bfd46d62dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e495e81fecf844a4ae4a15ca9cb0329c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e75e2e078b4246a9984fa0841de27a15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec62bc9001d349e696b8d82942e5b8c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4510cc71cf54df785fbe760b7dfc32c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f572376e2dbb437c95e1f62820d6f0d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb5e2db40e004e21a852c9f28740615c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
